{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "introduction",
      "metadata": {},
      "source": [
        "# Chapitre 1 👌🏼 : Introduction aux API et au Web Scraping 🕸️\n",
        "\n",
        "\n",
        "Dans ce cours, nous allons explorer comment interagir avec des API et comment effectuer du web scraping en Python.\n",
        "\n",
        "Tu vas voir comment utiliser requests et beautifoul soup ✅\n",
        "\n",
        "Si tu as la moindre question 🙌🏼 n'hésite pas.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "partie1-api",
      "metadata": {},
      "source": [
        "## Utilisation des API\n",
        "\n",
        "### Une API KESAKO 🫢 ?\n",
        "\n",
        "Une api de façon generale, c'est un bloc qui vous permet d'échanger des données entres deux types de services. \n",
        "\n",
        "Vous voulez faire le lien entre une base de données 💽 et une application mobile 📱 BAMM 💥 >> API\n",
        "\n",
        "En gros, vous la questionnez et elle vous renvoie un truc.\n",
        "\n",
        "Dans les faits c'est assez simple 😲:\n",
        "\n",
        "1. Une action de quelque chose ou de quelqu'un envoie des informations à l'api \n",
        "2. L'api récupère les infos les traitent (à ce moment, elle peut contacter une base de données, ou d'autres services)\n",
        "3. L'api (de façon général) renvoie quelque chose qui peut être lu du côtés de l'utilisateur\n",
        "\n",
        "Une api peut être utilisée pour effectuer, beaucoup, beaucoup, beaucoup de chose 🥵. En fonction des actions que nous allons lui demander de faire il convient d'utiliser la bonne méthode http.\n",
        "\n",
        "Pour utiliser une api, il faut de façon general :\n",
        "1. Utiliser une méthode **REST** (GET,POST ...)\n",
        "2. Avoir une **url**\n",
        "3. Accessoirement avec des paramètres\n",
        "\n",
        "<div style=\"text-align: center;\">\n",
        "<img src=\"./image/composeapi.png\" width=\"500\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3);\"/>\n",
        "</div>\n",
        "\n",
        "✅ De façon général, la réponse d'une api est dans le format Json. Qui est le plus souvent utilisé dans les retours d'api. Mais tu peux aussi avoir de l'xml ou autre format.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7ede9d0",
      "metadata": {},
      "source": [
        "#### 📡 Les 4 Méthodes Principales d’une API REST\n",
        "\n",
        "1.\tGET 📥\n",
        "\t- **Description** : Récupère des données depuis le serveur.\n",
        "  \n",
        "\t-\t**Exemple** : Obtenir la liste des utilisateurs.\n",
        "\t-\t**Usage** : Utilisé pour lire ou consulter des ressources sans les modifier.\n",
        "2.\tPOST 📨\n",
        "\t-\t**Description** : Envoie de nouvelles données au serveur pour créer une ressource.\n",
        "\t-\t**Exemple** : Ajouter un nouvel utilisateur.\n",
        "\t-\t**Usage** : Utilisé pour créer de nouvelles entrées dans la base de données.\n",
        "3.\t**PUT** 🔄\n",
        "\t-\t**Description** : Met à jour des données existantes sur le serveur.\n",
        "\t-\t**Exemple** : Modifier les informations d’un utilisateur existant.\n",
        "\t-\t**Usage** : Utilisé pour remplacer entièrement une ressource ou pour mettre à jour certaines de ses propriétés.\n",
        "4.\t**DELETE** 🗑️\n",
        "\t-\t**Description** : Supprime des données du serveur.\n",
        "\t-\t**Exemple** : Supprimer un utilisateur spécifique.\n",
        "\t-\t**Usage** : Utilisé pour enlever des ressources de la base de données.\n",
        "\n",
        " \n",
        "Dans le cadre de ce cours nous allons qu'utiliser la méthode **get** pour récupérer des donneés. Mais si tu souhaites t'instruire tu pourras lire cet article (après la master class):\n",
        "- 📚 [Explication des méthodes Rest](https://blog.postman.com/what-are-http-methods/)\n",
        " \n",
        "\n",
        "Dans notre cours nous allons l'utiliser pour récupérer des données et comprendre comment ajouter des paramètre aux besoins.   "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27fddc39",
      "metadata": {},
      "source": [
        "#### Le status code de la réponse api ✅\n",
        "Les codes d’état HTTP sont des nombres à trois chiffres renvoyés par un serveur en réponse à une requête HTTP effectuée par un client. Ils sont classés en différentes catégories selon leur première chiffre, indiquant le type de réponse.\n",
        "\n",
        "-\t1xx 🕒 : Informationnel – Indique que la requête est en cours de traitement.\n",
        "-\t2xx ✅ : Succès – La requête a été traitée avec succès.\n",
        "-\t3xx 🔄 : Redirection – Nécessite une action supplémentaire du client.\n",
        "-\t4xx ❌ : Erreurs du Client – Problème avec la requête envoyée par le client.\n",
        "-\t5xx 🚫 : Erreurs du Serveur – Problème côté serveur lors du traitement de la requête."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b026da8",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "### Un petit éxemple ✍🏽\n",
        "\n",
        "Nous allons prendre un exemple courant ! Imaginons que je souhaites aller récupérer des données sur l'open data de la région réunion (éxemple pris totalement au hasard) 😏\n",
        "\n",
        "\n",
        "- [Lien de l'open data hub de la Région Réunion](https://data.regionreunion.com/explore)\n",
        "\n",
        "\n",
        "\n",
        "<div style=\"text-align: center;\">\n",
        "<img src=\"./image/api.png\" width=\"300\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3);\"/>\n",
        "</div>\n",
        "\n",
        "1.\t📤 J’effectue ma requête avec l’URL du bloc précédent et avec la méthode GET.\n",
        "    -\tEnvoyer une demande pour obtenir des données spécifiques.\n",
        "2.\t🖥️ Le serveur réceptionne ma requête et vérifie les paramètres.\n",
        "    -\tLe serveur reçoit la demande et s’assure que toutes les informations nécessaires sont présentes et correctes.\n",
        "3.\t🔍 En fonction des paramètres, il demande à la base de données les informations dont il a besoin.\n",
        "    -\tLe serveur interroge la base de données en fonction des critères spécifiés dans la requête.\n",
        "4.\t📥 Il récupère les données.\n",
        "    -\tLes données demandées sont extraites de la base de données.\n",
        "5.\t🔄 Les retourne à l’utilisateur.\n",
        "\t    -\tLe serveur envoie les données récupérées en réponse à la requête initiale.\n",
        "\n",
        "\n",
        "Avec l'url que nous avons utiliser plus haut qui est la suivante :\n",
        "- [Url de l'api région en get](https://data.regionreunion.com//api/explore/v2.1/catalog/datasets/lieux-remarquables-lareunion-wssoubik/records?limit=20&refine=commune%3A%22Saint-Louis%22)\n",
        "\n",
        "Voici le résultat :\n",
        "<div style=\"text-align: center;\">\n",
        "<img src=\"./image/api-response.png\" width=\"300\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3);\"/>\n",
        "</div>\n",
        "\n",
        "J'ai bien les informations pour la commune de saint louis 🎉 \n",
        "\n",
        "**💥 Quand tu effectue une requête sur ton navigateur c'est un GET qui est effectué**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6eac51bc",
      "metadata": {},
      "source": [
        "Astuce ✌🏼:\n",
        "- Si tu souhaites avoir le json retour formatté dans ton navigateur tu peux installer (plus tard)\n",
        "  - [Basic json formatter pour firefox 🦊](https://addons.mozilla.org/en-US/firefox/addon/basic-json-formatter/)\n",
        "  - [Json formatter pour chrome 🏀](https://chromewebstore.google.com/detail/json-formatter/bcjindcccaagfpapjjmafapmmgkkhgoa?hl=en&pli=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "exemple-requests",
      "metadata": {},
      "source": [
        "### Éxercice 1 : Récupérer des données avec `requests`\n",
        "\n",
        "Normalement avec les prepwork vous avez déja du installer votre environnement python 🫣. Si ce n'est pas le cas installer rapidement requests avec la commande suivande:\n",
        "````\n",
        "pip install requests\n",
        "````\n",
        "**requests** est une bibliothèque Python pour envoyer des requêtes HTTP. Elle simplifie la communication avec des services web et des APIs en permettant aux développeurs d’effectuer facilement des opérations telles que **GET, POST, PUT, DELETE,** et bien d’autres, sans avoir à gérer les détails complexes du protocole HTTP.\n",
        "\n",
        "La première api que tu vas utiliser ici, possède l'url suivante :\n",
        "\n",
        "````\n",
        "url = \"http://localhost:1337/api/test-w-ts\"\n",
        "````\n",
        "\n",
        "Voici la réponse de l'api:\n",
        "\n",
        "<div style=\"text-align: center;\">\n",
        "<img src=\"./image/api_reponse.png\" width=\"300\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3);\"/>\n",
        "</div>\n",
        "\n",
        "\n",
        "<!-- ![Reponse de l'api](./image/api_reponse.png) -->\n",
        "\n",
        "Clic sur ce lien est tu verras la même chose :\n",
        "\n",
        "[Lien de l'api](http://localhost:1337/api/test-w-ts)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2edd6e87",
      "metadata": {},
      "source": [
        "Dans ce premier exercice tu vas:\n",
        "- Importer requests\n",
        "- Définir l'url de l'api \n",
        "- Effectuer ton get avec requests\n",
        "- Convertir la reponse en dictionnaire\n",
        "- Stocker le status et la réponse de l'api dans \n",
        "  - status_code \n",
        "  - api_response_data (⛔️ attention il faut le message de la réponse pour passer le test pas juste le dictionnaire)\n",
        "- afficher la reponsé de l'api qui doit être **\"Accés à l'api ok\"**\n",
        "- afficher le status de la réponse qui doit être \"**200**\"\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "code-requests",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Le status de la réponse: 200\n",
            "Ce dont j'ai besoin: \n",
            "  ---- Accés à l'api ok \n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "# URL de l'API\n",
        "url = \"http://localhost:1337/api/test-w-ts\"\n",
        "\n",
        "#J'effectue une requête GET\n",
        "response = requests.get(url)\n",
        "\n",
        "# Vérifier le statut de la réponse\n",
        "status_code = response.status_code\n",
        "api_response_data = response.json()[\"data\"][0][\"attributes\"][\"response\"]\n",
        "\n",
        "print(\"Le status de la réponse:\", status_code)\n",
        "\n",
        "# Ce dont j'ai besoin\n",
        "print(f\"Ce dont j'ai besoin: \\n  ---- {api_response_data}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abc9f612",
      "metadata": {},
      "source": [
        "Verifie tes résultats avec le test en dessous 🤞🏼:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "46968064",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "..\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------------\n",
            "Ran 2 tests in 0.004s\n",
            "\n",
            "OK\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Tous les tests ont réussi! ✅\n"
          ]
        }
      ],
      "source": [
        "import unittest\n",
        "from IPython.display import Markdown, display\n",
        "import test_api\n",
        "\n",
        "test_api.status_code = status_code\n",
        "test_api.api_response = api_response_data\n",
        "\n",
        "loader = unittest.TestLoader()\n",
        "suite = loader.loadTestsFromTestCase(test_api.TestApiResponse)\n",
        "\n",
        "runner = unittest.TextTestRunner()\n",
        "result = runner.run(suite)\n",
        "\n",
        "if result.wasSuccessful():\n",
        "    print(\"✅ Tous les tests ont réussi! ✅\")\n",
        "else:\n",
        "    print(\"❌ Échec des tests\")\n",
        "    for failure in result.failures:\n",
        "        print(failure)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31824fda",
      "metadata": {},
      "source": [
        "Si tu n'as ✅ Tous les tests ont réussi! ✅, essai de nouveau !"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9abea3f",
      "metadata": {},
      "source": [
        "### Éxércice 2 : Récupérer et parcourir des données\n",
        "\n",
        "Dans cet exercice, les choses deviennent un petit peu plus compiqué.. Un petit peu **promis** 🤞🏼\n",
        "\n",
        "L'url change pour cet exercice et tu vas utiliser la suivante :\n",
        "\n",
        "````\n",
        "url = http://localhost:1337/api/articles\n",
        "````\n",
        "\n",
        "Les api utilisent desfois des façon d'envoyer des paramètre de façon différentes. Ce qui est par contre assez commun, c'est d'avoir un **?** qui sépare l'url des paramètres que nous avons vu plus haut (dans le cas d'un get).\n",
        "\n",
        "En gros:\n",
        "- **url**/**?** **params**\n",
        "\n",
        "Dans cet exercice tu vas devoir lister l'ensemble des titres et des id que retourne l'url que je t'ai donné un peu plus haut. \n",
        "\n",
        "Cet api est generée par STRAPI et possède une documentation simple pour savoir comment donner en paramètres les champs dont j'ai besoin à mon api. \n",
        "- [Documentation de strapi](https://docs.strapi.io/dev-docs/api/rest/populate-select)\n",
        "\n",
        "\n",
        "Astuce 💡:\n",
        "- Check la section **Field Selection**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "004ee306",
      "metadata": {},
      "source": [
        "Ceux que tu vas devoir faire:\n",
        "1. Définir la bonne url \n",
        "2. Effectuer un get avec request\n",
        "3. Convertir la réponse en dictionnaire\n",
        "4. Faire une liste de l'ensemble des id dans la variable id_list\n",
        "5. faire une liste de l'ensemble des titres dans la variable id_titles\n",
        "6. Tester ton code "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "47cd7c7d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Comment jongler avec des baguettes magiques', 'Le guide ultime du sabre laser', 'Le secret du sourire de la Joconde', 'Comment survivre à une apocalypse zombie', 'Construire son armure en cave', 'Les meilleures pizzas pour tortues ninja', 'Faire ses courses en Batmobile', \"L'art du camouflage en forêt\", 'Les vertus du miel magique', 'Pourquoi les aliens adorent les vélos']\n"
          ]
        }
      ],
      "source": [
        "# Définir l'url de l'API\n",
        "url_articles = \"http://localhost:1337/api/articles?fields[0]=id&fields[1]=title\"\n",
        "\n",
        "# Faire une requête GET\n",
        "response = requests.get(url_articles)\n",
        "\n",
        "# Convertir la réponse en dictionnaire\n",
        "data = response.json()[\"data\"]\n",
        "\n",
        "# Faire une liste avec une list comprehension pour id_list et id_titles\n",
        "id_list= [dictionnary[\"id\"] for dictionnary in data]\n",
        "id_titles = [dictionnary[\"attributes\"][\"title\"] for dictionnary in data]\n",
        "print(id_titles)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14301fae",
      "metadata": {},
      "source": [
        "Verifie tes résultats avec le test en dessous 🤞🏼:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "76d19649",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "..\n",
            "----------------------------------------------------------------------\n",
            "Ran 2 tests in 0.004s\n",
            "\n",
            "OK\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div style=\"text-align: center;\">\n",
              "        <img src=\"./image/bravo.jpg\" width=\"300\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3);\"/>\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import test_api_2\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "test_api_2.id_list = id_list\n",
        "test_api_2.id_titles = id_titles\n",
        "\n",
        "loader = unittest.TestLoader()\n",
        "suite = loader.loadTestsFromTestCase(test_api_2.TestArticlesAPI)\n",
        "\n",
        "runner = unittest.TextTestRunner()\n",
        "result = runner.run(suite)\n",
        "\n",
        "if result.wasSuccessful():\n",
        "    display(HTML('''\n",
        "    <div style=\"text-align: center;\">\n",
        "        <img src=\"./image/bravo.jpg\" width=\"300\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3);\"/>\n",
        "    </div>\n",
        "    '''))\n",
        "else:\n",
        "    print(\"❌ Échec des tests\")\n",
        "    for failure in result.failures:\n",
        "        print(failure)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb95fc1d",
      "metadata": {},
      "source": [
        "#### À ce stade, tu gères déjà bien les trucs essentiels du web 🎉:\n",
        "\n",
        "-\tLes méthodes HTTP : Tu sais quand utiliser GET, POST, etc., pour interagir avec une API.\n",
        "-\tLes status codes : Genre le 200, 404, 500… tu sais direct si tout va bien ou si ça plante.\n",
        "-\tLes paramètres d’URL : Tu sais ajouter des filtres dans l’URL pour récupérer juste ce dont tu as besoin.\n",
        "-\tParser un JSON : T’es capable de récupérer des données d’une requête et les organiser en listes ou dicos."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffe9c32f",
      "metadata": {},
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "partie2-scraping",
      "metadata": {},
      "source": [
        "## Partie 2 : Web Scraping avec BeautifulSoup\n",
        "\n",
        "### Qu'est-ce que le Web Scraping ?\n",
        "\n",
        "Le web scraping, c’est l’art d’extraire des infos d’un site web de manière automatisée.\n",
        "\n",
        "Dans la partie précédente, je t’ai donné la grande nouvelle… Toutes les pages web sont accessibles via un simple **GET**.\n",
        "\n",
        "➡️  Mais parfois, les données que tu attends ne sont pas là directement. Au lieu des articles, tu ne récupères que le squelette 🩻 du site. Pourquoi ? Parce que le site fait peut-être appel à une API en arrière-plan qui met du temps à répondre. Résultat : tu te retrouves avec une page vide ou incomplète.\n",
        "\n",
        "Nous n'aurons pas à traiter cet éxemple dans ce cours, mais si tu veux une piste pour régler ce type de problème tu peux te tourner vers **Selenium** pour scraper des sites en python. \n",
        "\n",
        "**En résumé :**\n",
        "\n",
        "-\tSi la page est rendue via JavaScript (comme un site dynamique où les données arrivent après un certain temps), utilise **Selenium**.\n",
        "-\tSi les données sont dans le HTML dès le chargement initial (pas besoin d’attendre du JS), alors **requests** + **BeautifulSoup** suffisent.\n",
        "\n",
        "**BeautifulSoup** 🍲, c’est une bibliothèque Python qui te permet de naviguer et extraire des données facilement à partir de pages HTML ou XML. En gros, elle t’aide à trouver et parser des éléments dans une page web, comme des titres, des liens, des paragraphes, etc.\n",
        "\n",
        "Tu lui donnes le contenu **HTML** d’une page, et elle te permet de chercher rapidement des trucs comme des **balises** , des **classes**, des **ID**, ou d’autres éléments pour les **scraper**.\n",
        "\n",
        "C’est super pratique quand tu utilises requests ou un autre moyen pour récupérer le HTML d’une page et que tu veux **extraire** des infos spécifiques.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "exemple-scraping",
      "metadata": {},
      "source": [
        "### Éxercice 1 : Extraire les titres des articles d'une page web \n",
        "\n",
        "Rendez-vous 👮🏼‍♂️  sur :\n",
        "- [HackerNews](https://news.ycombinator.com/)\n",
        "\n",
        "Vous êtes censé voir un ensemble d'article un peu comme ça:\n",
        "\n",
        "<div style=\"text-align: center;\">\n",
        "<img src=\"./image/hackernews.png\" width=\"500\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3);\"/>\n",
        "</div>\n",
        "\n",
        "On peut déja identifier une structure qui se répéte plusieurs fois :\n",
        "  - Des titres\n",
        "  - Des auteurs\n",
        "  - des dates \n",
        "  - des sites \n",
        "\n",
        "Dans toutes cette répétition d'article on peut y voir un composant qui revient très souvent ⬇️ ⬇️ ⬇️:\n",
        "<div style=\"text-align: center;\">\n",
        "<img src=\"./image/bloc_h.png\" width=\"500\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3);\"/>\n",
        "</div>\n",
        "\n",
        "Pour cet exercice, il va falloir **scraper** sur la page d'hacker news 🏴‍☠️:\n",
        "- Chaque titre \n",
        "- Chaque auteurs\n",
        "\n",
        "\n",
        "Mais **JAMY** comment on fait ca ? 🤓\n",
        "\n",
        "<div style=\"text-align: center;\">\n",
        "<img src=\"./image/buthow.jpg\" width=\"300\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3);\"/>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a702562e",
      "metadata": {},
      "source": [
        "Quand tu vas sur hacker news, que tu fais clic droit et enfin voir le code source:\n",
        "<div style=\"text-align: center;\">\n",
        "<img src=\"./image/option.png\" width=\"500\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3);\"/>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tu arrives sur une page du style:\n",
        "\n",
        "<div style=\"text-align: center;\">\n",
        "<img src=\"./image/sourhn.png\" width=\"700\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3);\"/>\n",
        "</div>\n",
        "\n",
        "Tu commence à avoir une idée ?  🧠\n",
        "\n",
        "Le concept est en soit assez simple, tu dois: \n",
        "1. Identifier dans le code source de la page les informations dont tu as besoin \n",
        "2. Faire une request GET sur le site de hacker news\n",
        "3. Parser tes données avec beautifoulsoup > Donc le code html de la page\n",
        "4. Isoler les élèments dont tu as besoin\n",
        "5. Placer dans une liste tous les titres et tous les auteurs\n",
        "\n",
        "\n",
        "**No worries 🕵🏼‍♂️ nous allons le faire ensemble.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "code-scraping",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "La liste des titres des articles d'hackerNews :\n",
            "['Nextcloud: Open-Source Cloud Apps (nextcloud.com)', 'Sanding UI (jim-nielsen.com)', 'Flappy Bird for Android, only C, under 100KB (github.com/vadimboev)', 'What happened to the Japanese PC platforms? (mistys-internet.website)', 'Fable at 20: a uniquely British video game with a complex legacy (theguardian.com)', 'Show HN: PDF to MD by LLMs – Extract Text/Tables/Image Descriptives by GPT4o (github.com/yigitkonur)', 'Scientific Visualization: Python + Matplotlib (2021) (github.com/rougier)', \"Infineon's CO2 Sensor Monitors Indoor Air Quality (allaboutcircuits.com)\", \"Surely That Can't Change Sign Back and Forth (Machine Learning Model Homology) (win-vector.com)\", \"FCC wants all phones unlocked in sixty days, AT&T and T-Mobile aren't so keen (androidauthority.com)\", 'What Is a Particle? (2020) (quantamagazine.org)', 'LsCs is a cross platform C++ GUI library focused on Medical Devices (lscs-software.com)', 'Open-Source CLI tool to inspect databases fast (github.com/peepdb-dev)', 'Scaling up linear programming with PDLP (research.google)', 'Twenty Years of FM Synthesis Inside Ableton Live (roberthenke.com)', 'Applied Mathematical Programming (web.mit.edu)', 'Logging all C++ destructors, poor mans run-time tracing (raymii.org)', 'Social Initiation (truman.edu)', 'Emacs Speaks Statistics (r-project.org)', 'They stole my voice with AI (jeffgeerling.com)', 'LHC experiments at CERN observe quantum entanglement at the highest energy yet (home.cern)', 'Analyzing the OpenAPI Tooling Ecosystem (modern-json-schema.com)', 'Stupid Problems Require Stupid Solutions (Cloudflare Is Breaking My SVGs) (lloydatkinson.net)', 'Restish: CLI for interacting with REST-ish HTTP APIs with some nice features (rest.sh)', 'Ultra high-resolution image of The Night Watch (2022) (rijksmuseum.nl)', 'Flow Computing aims to boost CPUs with ‘parallel processing units’ (ieee.org)', 'Show HN: Parse your Postgres queries into a fully-typed AST in TypeScript (github.com/pg-nano)', 'Scientists find new blood group after 50-year mystery (bbc.com)', 'Mount Unix system into Common Lisp image (github.com/puellaemagicae)', 'Substack (YC W18) Is Hiring Machine Learning Engineers (grnh.se)']\n",
            " ainsi que le nombre d'élèments de cette liste: 30\n",
            "La liste des auteurs des articles d'hackerNews :\n",
            "['tomrod', 'roosgit', 'lostmsu', 'zdw', 'n1b0m', 'yigitkonur35', 'danso', 'WaitWaitWha', 'jmount', 'miles', 'sblank', 'jandeboevrie', 'maverick98', 'bookofjoe', 'gregsadetsky', 'ibobev', 'jandeboevrie', 'yamrzou', 'smartmic', 'sounds', 'gmays', 'handrews', 'thunderbong', 'thunderbong', 'lhoff', 'rbanffy', 'aleclarsoniv', 'tomrod', 'BoingBoomTschak']\n",
            " ainsi que le nombre d'élèments de cette liste: 29\n"
          ]
        }
      ],
      "source": [
        "#Importer les lib dont j'ai besoin\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# URL de la page à scraper\n",
        "url = \"https://news.ycombinator.com/\"\n",
        "\n",
        "# Obtenir le contenu de la page\n",
        "response = requests.get(url)\n",
        "\n",
        "# Parser le HTML\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# Trouver tous les titres d'articles avec un find all sur des élèments unique\n",
        "titles = soup.find_all('span', class_='titleline')\n",
        "title_list=[i.text  for i in titles]\n",
        "\n",
        "author = soup.find_all('a', class_='hnuser')\n",
        "author_list=[i.text  for i in author]\n",
        "\n",
        "print(f\"La liste des titres des articles d'hackerNews :\\n{title_list}\\n ainsi que le nombre d'élèments de cette liste: {len(title_list)}\")\n",
        "print(f\"La liste des auteurs des articles d'hackerNews :\\n{author_list}\\n ainsi que le nombre d'élèments de cette liste: {len(author_list)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2851bdf6",
      "metadata": {},
      "source": [
        "**Good 🎉**\n",
        "\n",
        "Mais on a un petit problème... 🤷🏽‍♂️\n",
        "La liste des titres, n'a pas la même longueur que celle des auteurs. (en espérant que cela soit aussi le cas le jour de la masterclass 🥲)\n",
        "Il faut donc améliorer ce script pour que cela soit exploitable peut-être pour une futur api ? \n",
        "Convertissons en dictionnaire nos deux listes précédentes et de façon structurer s'il vous plaît !\n",
        "\n",
        "Le début reste le même ..\n",
        "\n",
        "À l'inverse de tout à l'heure, au lieu de cibler directement les élèments dont j'ai besoin je vais éssayer de trouver une div plus haute dans la hierarchie qui englobe tout mon composant. Et j'enchaine par une for loop afin de récupérer titre et auteur que je placerais dans une liste de dictionnaire !! 🥵"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "id": "3940ebd6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['41578516', '41612154', '41614663', '41612984', '41573013', '41574050', '41615102', '41577916', '41616455', '41572437', '41587971', '41612049', '41614126', '41611571', '41609670', '41611965', '41614949', '41608489', '41611948', '41613722', '41612002', '41611681', '41616653', '41614567', '41608648', '41576956', '41611613', '41612665', '41579601', '41616540']\n",
            "[{'id': '41578516', 'title': 'HTTP: , FTP:, and Dict:?', 'author': 'edent'}, {'id': '41612154', 'title': 'Sanding UI', 'author': 'roosgit'}, {'id': '41614663', 'title': 'Flappy Bird for Android, only C, under 100KB', 'author': 'lostmsu'}, {'id': '41612984', 'title': 'What happened to the Japanese PC platforms?', 'author': 'zdw'}, {'id': '41573013', 'title': 'Machine Learning Model Homotopy', 'author': 'jmount'}, {'id': '41574050', 'title': 'Ask HN: Help me restore the LCD displays on classic samplers so I can use them', 'author': 'ThinkBeat'}, {'id': '41615102', 'title': 'Nextcloud: Open-Source Cloud Apps', 'author': 'tomrod'}, {'id': '41577916', 'title': 'Fable at 20: a uniquely British video game with a complex legacy', 'author': 'n1b0m'}, {'id': '41616455', 'title': 'Motion (YC W20) Is Hiring a Quant Algo Developer', 'author': None}, {'id': '41572437', 'title': 'Scientific Visualization: Python + Matplotlib (2021)', 'author': 'danso'}, {'id': '41587971', 'title': 'Development from the outside in: Can Irvine become a central city?', 'author': 'surprisetalk'}, {'id': '41612049', 'title': 'What Is a Particle? (2020)', 'author': 'sblank'}, {'id': '41614126', 'title': 'Show HN: PDF to MD by LLMs – Extract Text/Tables/Image Descriptives by GPT4o', 'author': 'yigitkonur35'}, {'id': '41611571', 'title': 'Applied Mathematical Programming', 'author': 'ibobev'}, {'id': '41609670', 'title': 'Scaling up linear programming with PDLP', 'author': 'bookofjoe'}, {'id': '41611965', 'title': \"Infineon's CO2 Sensor Monitors Indoor Air Quality\", 'author': 'WaitWaitWha'}, {'id': '41614949', 'title': 'LsCs is a cross platform C++ GUI library focused on Medical Devices', 'author': 'jandeboevrie'}, {'id': '41608489', 'title': 'Open-Source CLI tool to inspect databases fast', 'author': 'maverick98'}, {'id': '41611948', 'title': 'Logging all C++ destructors, poor mans run-time tracing', 'author': 'jandeboevrie'}, {'id': '41613722', 'title': 'Twenty Years of FM Synthesis Inside Ableton Live', 'author': 'gregsadetsky'}, {'id': '41612002', 'title': 'Analyzing the OpenAPI Tooling Ecosystem', 'author': 'handrews'}, {'id': '41611681', 'title': 'Emacs Speaks Statistics', 'author': 'smartmic'}, {'id': '41616653', 'title': 'The sorry state of Java deserialization', 'author': 'kevincox'}, {'id': '41614567', 'title': 'Stupid Problems Require Stupid Solutions (Cloudflare Is Breaking My SVGs)', 'author': 'thunderbong'}, {'id': '41608648', 'title': 'Ultra high-resolution image of The Night Watch (2022)', 'author': 'lhoff'}, {'id': '41576956', 'title': 'Show HN: Parse your Postgres queries into a fully-typed AST in TypeScript', 'author': 'aleclarsoniv'}, {'id': '41611613', 'title': 'LHC experiments at CERN observe quantum entanglement at the highest energy yet', 'author': 'gmays'}, {'id': '41612665', 'title': 'Flow Computing aims to boost CPUs with ‘parallel processing units’', 'author': 'rbanffy'}, {'id': '41579601', 'title': 'Restish: CLI for interacting with REST-ish HTTP APIs with some nice features', 'author': 'thunderbong'}, {'id': '41616540', 'title': \"Bruce Schneier: Israel's Pager Attacks Have Changed the World\", 'author': 'kawera'}]\n"
          ]
        }
      ],
      "source": [
        "# URL de la page à scraper\n",
        "url = \"https://news.ycombinator.com/\"\n",
        "\n",
        "# Obtenir le contenu de la page\n",
        "response = requests.get(url)\n",
        "\n",
        "# Parser le HTML\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# J'identifie le point d'accroche possibe\n",
        "tr_tags = soup.find_all('tr', class_='athing')\n",
        "\n",
        "#J'ajoute mes id à ma liste tr_tags_list en effectuant le get je récupére l'id de mon tag tr\n",
        "tr_tags_list = [i.get('id') for i in tr_tags]\n",
        "\n",
        "# tr_title = soup.find('tr', id='41614949').find('span', class_='titleline').find('a').string\n",
        "# tr_auteur = soup.find('span', id='score_41614949').find_parent('span', class_='subline').find('a',class_=\"hnuser\").string\n",
        "\n",
        "#Fonction lambda pour obtenir le titre et l'auteur\n",
        "get_tr_title = lambda id: (soup.find('tr', id=id).find('span', class_='titleline').find('a').string\n",
        "                           if soup.find('tr', id=id) and soup.find('tr', id=id).find('span', class_='titleline') and\n",
        "                           soup.find('tr', id=id).find('span', class_='titleline').find('a') else None)\n",
        "\n",
        "#Fonction lambda pour obtenir l'auteur\n",
        "get_tr_auteur = lambda id: (soup.find('span', id=f'score_{id}').find_parent('span', class_='subline').find('a', class_=\"hnuser\").string\n",
        "                            if soup.find('span', id=f'score_{id}') and\n",
        "                            soup.find('span', id=f'score_{id}').find_parent('span', class_='subline') and\n",
        "                            soup.find('span', id=f'score_{id}').find_parent('span', class_='subline').find('a', class_=\"hnuser\") else None)\n",
        "\n",
        "final_dict = [{ \"id\": key, \"title\": get_tr_title(key), \"author\": get_tr_auteur(key)} for key in tr_tags_list]\n",
        "print(final_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90a02006",
      "metadata": {},
      "source": [
        "Ok, nous allons y aller doucement. 🐢\n",
        "Je vais t'éxpliquer en détail comment ca fonctionne. \n",
        "\n",
        "Premièrement, dans le code source je remarque que je ne peux pas boucler sur une balise avec un **find_all**.\n",
        "\n",
        "Le find_all va me **grouper** tous ceux qu'il va trouver avec les conditions que je lui ai donné ici :\n",
        "- Les balises ```tr```\n",
        "- Qui ont  une balise enfant ```span``` qui possède la classe ```subline```\n",
        "\n",
        "Si cette condition n'est pas réspécté le ```tr``` n'est pas dans ma liste retour. \n",
        "\n",
        "Mon titre et mon auteur sont dans deux balises séparées ... C'est embétant. \n",
        "Nous le voyons bien dans l'image suivante:\n",
        "<div style=\"text-align: center;\">\n",
        "<img src=\"./image/group.png\" width=\"700\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3);\"/>\n",
        "</div>\n",
        "\n",
        "Il faut donc trouver une solution. \n",
        "Pour ce faire on remarque ca dans le code source: \n",
        "<div style=\"text-align: center;\">\n",
        "<img src=\"./image/reflexion.png\" width=\"700\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3);\"/>\n",
        "</div>\n",
        "\n",
        "Il y a donc bien toujours une **solution** 🎉 \n",
        "\n",
        "Pour récupérer le titre voila ce que je fais dans cette lambda function:\n",
        "\n",
        "````python \n",
        "soup.find('tr', id=id).find('span', class_='titleline').find('a').string\n",
        "````\n",
        "C'est mieux éxpliqué en image: \n",
        "<div style=\"text-align: center;\">\n",
        "<img src=\"./image/firstsoup.png\" width=\"700\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3);\"/>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "explication-scraping",
      "metadata": {},
      "source": [
        "Pour le deuxième bloc c'est un tout petit peu plus tricky:\n",
        "````python\n",
        "soup.find('span', id=f'score_{id}').find_parent('span', class_='subline').find('a', class_=\"hnuser\").string\n",
        "````\n",
        "<div style=\"text-align: center;\">\n",
        "<img src=\"./image/groupsoup2.png\" width=\"700\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3);\"/>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "conclusion",
      "metadata": {},
      "source": [
        "**Well done !! 👌🏼\n",
        "Maintenant c'est à vous de jouer dans l'éxercice 2!**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d88d4db",
      "metadata": {},
      "source": [
        "### Éxercice 2 : À votre tour de scraper !!! ⭐️\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1a1301d",
      "metadata": {},
      "source": [
        "Dans le cadre de cet masterClass, on vous mets gracieusement à disposition un site test de scraping 🎉: \n",
        "- [Site Scraping masterclass 1](http://localhost:3000)\n",
        "\n",
        "Le but de cet exercice va être le suivant, tu dois avoir exactement les mêmes resultats que cette requête api:\n",
        "\n",
        "````python\n",
        "url_articles = \"http://localhost:1337/api/articles?fields[0]=id&fields[1]=title&fields[2]=body\"\n",
        "````\n",
        "Qui ressemble à cela:\n",
        "<div style=\"text-align: center;\">\n",
        "<img src=\"./image/newrequeststrapi.png\" width=\"900\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3);\"/>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "751a5c4c",
      "metadata": {},
      "source": [
        "Sur le site tu vas avoir une architecture comme celle la:\n",
        "\n",
        "1. Pour la liste des articles\n",
        "<div style=\"text-align: center;\">\n",
        "<img src=\"./image/whatiwant1.png\" width=\"700\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3);\"/>\n",
        "</div>\n",
        "\n",
        "2. Pour le corp des articles (le body)\n",
        "<div style=\"text-align: center;\">\n",
        "<img src=\"./image/whatiwant2.png\" width=\"700\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3);\"/>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cc6dee8",
      "metadata": {},
      "source": [
        "Il y à deux petits **pièges** 😬:\n",
        "- Le site à une pagination, promis je ne l'ai pas fait éxprès 🤞🏼\n",
        "- Le body des article se trouve à une autre URL que celle de la page d'acceuil 😇\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93cc1aaa",
      "metadata": {},
      "source": [
        "**Comment te lancer dans cet exercice ? 🚀**\n",
        "1.\tAnalyse bien les données du JSON que tu obtiens avec la requête vers url de l’API précédente. 🧐\n",
        "2.\tRegarde l’URL de la page d’accueil du site et observe comment fonctionne la pagination. Est-ce que l’URL change ou pas ? 🔄\n",
        "3.\tVérifie la page article : de quoi est-elle composée ? Est-ce que j’ai des informations sur la page d’accueil qui me permettent d’accéder directement à la page article ? 🔗\n",
        "4. Est-ce que je peux scraper tout le site avec un simple GET ? ❓ (👉 NON ❗)\n",
        "5. Combien de page j'ai ??? 🙄"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fef1ecc",
      "metadata": {},
      "source": [
        "🎯 Ton objectif : créer une liste de dictionnaires où chaque objet contiendra les champs suivants (bien remplis, bien sûr) :\n",
        "\n",
        "```python\n",
        "scrap_site_data = [\n",
        "  {\"id\": 1, \n",
        "  \"title\": \"Un titre random\", \n",
        "  \"body\": \"Un body random\"},\n",
        "  # etc...\n",
        "]\n",
        "```\n",
        "\n",
        "📋 Pour chaque élément, assure-toi d’inclure :\n",
        "\n",
        "-\tid : l’identifiant unique de l’objet\n",
        "-\ttitle : le titre de l’article ou de la section\n",
        "-\tbody : le contenu ou un résumé de l’article\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c603d937",
      "metadata": {},
      "source": [
        "🚀 Laisse-moi te filer un coup de pouce :\n",
        "\n",
        "-\tL’URL d’un article ressemble à ça : ```/article/{id}```\n",
        "-\tPour naviguer entre les pages, tu dois simplement ajouter ce paramètre à l’URL : ```?page={pageNumber}```.\n",
        "-\tPour trouver l’id… je te laisse fouiller un peu ! 🔍😉 Peut-être dans le code source de la page ? I dont know 🤷🏽‍♂️\n",
        "\n",
        "\n",
        "Voila la checklist qu'on doit valider:\n",
        "- ⬜️ Connaître le nombre de pages de façon programmatique\n",
        "- ⬜️ Scraper le nombre de pages disponibles\n",
        "- ⬜️ Accéder à chaque page pour scraper le body d'un article\n",
        "\n",
        "<div style=\"text-align: center;\">\n",
        "<img src=\"./image/justdoit.jpg\" width=\"400\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3);\"/>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d03be90",
      "metadata": {},
      "source": [
        "##### Étape 1 - Récupère le nombre de page 📖"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "id": "45b85fb6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nombre de page: 2\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "urlToGet='http://localhost:3000'\n",
        "#Je récupère la home page de mon site\n",
        "website = requests.get(urlToGet)\n",
        "\n",
        "#Je le parse avec Bs4\n",
        "soup = BeautifulSoup(website.text, 'html.parser')\n",
        "#Maintenant voyons voir combien de page j'ai\n",
        "pages = soup.find_all('a', class_=re.compile(r'^Home_pagination'))\n",
        "nbPages=len(pages)\n",
        "print(f\"Nombre de page: {nbPages}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c2d55dc",
      "metadata": {},
      "source": [
        "Dans le code source 💾 de cette page voila ce que je remarque:\n",
        "<div style=\"text-align: center;\">\n",
        "<img src=\"./image/pagination.png\" width=\"700\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3);\"/>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9882e48c",
      "metadata": {},
      "source": [
        "Mais le **gTxG4** ou encore le **ro1Hj** me fait un peu peur 😱. Du coup, je pense qu’il y a de fortes chances que Home_pagination reste fixe, mais que cet ID mystérieux, probablement généré dynamiquement par la technologie du site, change régulièrement.\n",
        " \n",
        "C’est pour cela que j’utilise cette commande :\n",
        "```python\n",
        "pages = soup.find_all('a', class_=re.compile(r'^Home_pagination'))\n",
        "```\n",
        "\n",
        "Elle demande de chercher la balise ```a``` qui contient une classe commençant par ```Home_pagination```. J’utilise une expression régulière pour m’assurer que cette donnée est bien présente : le symbole ```^``` signifie “**commence par**”.\n",
        "\n",
        "➡️➡️➡️  [Si vous voulez en apprendre plus sur les éxpressions régulieres](https://www.rexegg.com/regex-quickstart.php)  ⬅️⬅️⬅️\n",
        "\n",
        "Notre checklist : \n",
        "- ✅ Connaître le nombre de pages de façon programmatique\n",
        "- ⬜️ Scraper le nombre de pages disponibles\n",
        "- ⬜️ Accéder à chaque page pour scraper le body d'un article\n",
        "\n",
        "Et maintenant, en route pour le grand scrapathon sur le nombre de pages défini plus haut ! 🎉🚀\n",
        "\n",
        "##### Étape 2 - Scraper les n pages et ... accéder à chaque page ...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "id": "840eed5a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'id': '2', 'title': 'Comment jongler avec des baguettes magiques', 'body': 'Harry Potter nous raconte comment il a appris à jongler avec des baguettes magiques sans accident grave. Après un incident fâcheux avec Ron et une transformation en escargot, il a perfectionné sa technique. Maintenant, il ne transforme plus ses amis, mais il conseille de ne pas jongler avec des baguettes empruntées. Elles ont souvent un caractère capricieux et pourraient décider d’invoquer un Basilic au mauvais moment. Bref, le jonglage magique : à pratiquer avec modération !'}, {'id': '3', 'title': 'Le guide ultime du sabre laser', 'body': \"Luke Skywalker nous explique que manier un sabre laser, ce n'est pas juste un exercice de style, mais un art ancestral. Il raconte comment son premier duel contre Dark Vador l’a aidé à mieux comprendre l’équilibre entre la lumière et l’obscurité. Il recommande de commencer avec des melons avant de passer à des combats réels. Si vous vous trouvez à court de batterie, pas de panique : un Jedi astucieux trouvera toujours un chargeur dans une galaxie lointaine. Et rappelez-vous : la Force doit être avec vous, sinon ça fait mal !\"}, {'id': '4', 'title': 'Le secret du sourire de la Joconde', 'body': 'Sherlock Holmes nous dévoile, après des années de réflexion, la raison du sourire de la Joconde. Ce n’est ni un secret romantique, ni un complot historique, mais plutôt la conséquence d’une blague secrète racontée par Léonard de Vinci pendant la séance de pose. Holmes a découvert des notes cachées dans les marges du carnet de Vinci, indiquant qu’il racontait une blague sur des pigeons et des alchimistes. Voilà pourquoi la Joconde sourit : elle réprime un fou rire dû à la blague la plus ancienne de l’histoire de l’art !'}, {'id': '5', 'title': 'Comment survivre à une apocalypse zombie', 'body': \"Rick Grimes, héros de The Walking Dead, partage ses astuces pour survivre à une apocalypse zombie. Il explique que courir n'est pas toujours la meilleure solution, surtout si vous portez des bottes de cow-boy. Il recommande aussi de garder toujours un tournevis à portée de main, car vous ne savez jamais quand vous en aurez besoin pour réparer une porte... ou un zombie. Son dernier conseil ? Apprenez à aimer les conserves. Elles sont à la fois nourrissantes et suffisamment lourdes pour assommer un zombie affamé.\"}, {'id': '6', 'title': 'Construire son armure en cave', 'body': \"Tony Stark, alias Iron Man, partage ses astuces pour créer une armure de haute technologie avec un budget réduit. Il raconte comment, au début de sa carrière, il a construit sa première armure avec des pièces récupérées dans une cave poussiéreuse. Son conseil principal : n’oubliez jamais les aimants, ils sont essentiels pour que les pièces tiennent ensemble. Si vous n'avez pas de réacteur Arc à portée de main, Stark recommande de faire preuve de créativité avec des batteries de voiture et quelques ampoules LED pour un look à couper le souffle.\"}, {'id': '7', 'title': 'Les meilleures pizzas pour tortues ninja', 'body': \"Michelangelo, la plus gourmande des Tortues Ninja, nous partage ses recettes secrètes de pizzas. Il conseille toujours de rajouter une bonne dose de fromage fondant, et surtout de ne jamais oublier la touche finale : les anchois radioactifs. Selon lui, une pizza sans un peu de mutagène n’est pas une vraie pizza. Mais attention, il met en garde : les effets secondaires peuvent inclure des superpouvoirs inattendus ou une envie soudaine de combattre des ninjas. Bref, avec ces recettes, c'est la pizza du futur !\"}, {'id': '8', 'title': 'Faire ses courses en Batmobile', 'body': 'Bruce Wayne, alias Batman, partage les défis inattendus qu’il rencontre lorsqu’il utilise la Batmobile pour faire ses courses. Il explique que même si la Batmobile est rapide, se garer dans le parking du supermarché peut être un cauchemar. En plus, les courses prennent plus de place qu’on ne le pense dans un véhicule conçu pour la chasse aux criminels. Il recommande d’opter pour un simple panier plutôt qu’un chariot, car les missiles embarqués prennent déjà beaucoup de place. Son dernier conseil : éviter les heures de pointe, même en Batmobile.'}, {'id': '9', 'title': \"L'art du camouflage en forêt\", 'body': 'Katniss Everdeen, héroïne de Hunger Games, nous apprend comment se fondre dans le décor comme un pro. Elle recommande de toujours avoir à portée de main de la boue et quelques feuilles pour un camouflage rapide. Mais attention, se camoufler ne veut pas dire disparaître complètement : Katniss explique qu’il faut savoir choisir le bon moment pour bondir et décocher une flèche. Elle raconte aussi comment elle a utilisé ces techniques pour échapper à plusieurs pièges mortels et décrocher la victoire.'}, {'id': '10', 'title': 'Les vertus du miel magique', 'body': \"Winnie l'Ourson partage ses réflexions profondes sur l’importance du miel dans sa vie. Il explique que le miel, au-delà de son goût délicieux, est un véritable élixir de bonheur. Selon Winnie, chaque pot de miel raconte une histoire, une aventure en forêt avec ses amis. Il recommande de toujours avoir un pot à portée de main pour les moments de réflexion philosophique. Cependant, il met en garde : le miel est un trésor à partager avec ses amis, car tout est meilleur quand on est bien entouré.\"}, {'id': '11', 'title': 'Pourquoi les aliens adorent les vélos', 'body': 'E.T., le célèbre extraterrestre, nous explique pourquoi il préfère les balades à vélo plutôt que de voler en soucoupe volante. Selon lui, le vélo offre une sensation de liberté que les voyages interstellaires ne peuvent pas égaler. Il raconte comment, lors de sa première balade sous la pleine lune avec Elliott, il a ressenti un lien particulier avec la Terre et ses habitants. E.T. conseille à tout le monde de prendre le temps d’apprécier une balade à vélo et de ne pas toujours chercher des moyens de transport plus rapides.'}]\n"
          ]
        }
      ],
      "source": [
        "urlToGet='http://localhost:3000'\n",
        "\n",
        "get_article_body = lambda articleSoup: articleSoup.find('p', class_=re.compile(r'^ArticlePage_body')).string\n",
        "get_article_title = lambda titleSoup: titleSoup.find('h2', class_=re.compile(r'^ArticleCard_articleTitle')).string\n",
        "\n",
        "listResult = []\n",
        "for page in range (1,nbPages+1):\n",
        "    res = requests.get(f'{urlToGet}/?page={page}')\n",
        "    soup = BeautifulSoup(res.text, 'html.parser')\n",
        "\n",
        "    allMyArticleByPage = soup.find_all('div', class_=re.compile(r'^ArticleCard_articleCard'))\n",
        "\n",
        "    for article in allMyArticleByPage:\n",
        "        article_id = article.get('id').split('-')[1]\n",
        "        title = get_article_title(article)\n",
        "        articleRes = requests.get(f'{urlToGet}/article/{article_id}')\n",
        "        articleSoup = BeautifulSoup(articleRes.text, 'html.parser')\n",
        "        body = get_article_body(articleSoup)\n",
        "        listResult.append({\"id\": article_id, \"title\": title, \"body\": body})\n",
        "\n",
        "print(listResult)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "973eb237",
      "metadata": {},
      "source": [
        "**Notre checklist 🎉:**\n",
        "- ✅ Connaître le nombre de pages de façon programmatique\n",
        "- ✅ Scraper le nombre de pages disponibles\n",
        "- ✅ Accéder à chaque page pour scraper le body d'un article\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "064d5033",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
