{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "introduction",
      "metadata": {},
      "source": [
        "# Chapitre 1 👌🏼 : Introduction aux API et au Web Scraping 🕸️\n",
        "\n",
        "\n",
        "Dans ce cours, nous allons explorer comment interagir avec des API et comment effectuer du web scraping en Python.\n",
        "\n",
        "Tu vas voir comment utiliser requests et beautifoul soup ✅\n",
        "\n",
        "Si tu as la moindre question 🙌🏼 n'hésite pas.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "partie1-api",
      "metadata": {},
      "source": [
        "## Utilisation des API\n",
        "\n",
        "### Une API KESAKO 🫢 ?\n",
        "\n",
        "Une api de façon generale, c'est un bloc qui vous permet d'échanger des données entres deux types de services. \n",
        "\n",
        "Vous voulez faire le lien entre une base de données 💽 et une application mobile 📱 BAMM 💥 >> API\n",
        "\n",
        "En gros, vous la questionnez et elle vous renvoie un truc.\n",
        "\n",
        "Dans les faits c'est assez simple 😲:\n",
        "\n",
        "1. Une action de quelque chose ou de quelqu'un envoie des informations à l'api \n",
        "2. L'api récupère les infos les traitent (à ce moment, elle peut contacter une base de données, ou d'autres services)\n",
        "3. L'api (de façon général) renvoie quelque chose qui peut être lu du côtés de l'utilisateur\n",
        "\n",
        "Une api peut être utilisée pour effectuer, beaucoup, beaucoup, beaucoup de chose 🥵. En fonction des actions que nous allons lui demander de faire il convient d'utiliser la bonne méthode http.\n",
        "\n",
        "Pour utiliser une api, il faut de façon general :\n",
        "1. Utiliser une méthode **REST** (GET,POST ...)\n",
        "2. Avoir une **url**\n",
        "3. Accessoirement avec des paramètres\n",
        "\n",
        "<div style=\"text-align: center;\">\n",
        "<img src=\"./image/composeapi.png\" width=\"500\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3);border-radius: 10px;\"/>\n",
        "  <figcaption>Schéma URL</figcaption>\n",
        "\n",
        "</div>\n",
        "\n",
        "✅ De façon général, la réponse d'une api est dans le format Json. Qui est le plus souvent utilisé dans les retours d'api. Mais tu peux aussi avoir de l'xml ou autre format.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7ede9d0",
      "metadata": {},
      "source": [
        "#### 📡 Les 4 Méthodes Principales d’une API REST\n",
        "\n",
        "1.\t**GET** 📥\n",
        "\t- **Description** : Récupère des données depuis le serveur.\n",
        "  \n",
        "\t-\t**Exemple** : Obtenir la liste des utilisateurs.\n",
        "\t-\t**Usage** : Utilisé pour lire ou consulter des ressources sans les modifier.\n",
        "2.\t**POST** 📨\n",
        "\t-\t**Description** : Envoie de nouvelles données au serveur pour créer une ressource.\n",
        "\t-\t**Exemple** : Ajouter un nouvel utilisateur.\n",
        "\t-\t**Usage** : Utilisé pour créer de nouvelles entrées dans la base de données.\n",
        "3.\t**PUT** 🔄\n",
        "\t-\t**Description** : Met à jour des données existantes sur le serveur.\n",
        "\t-\t**Exemple** : Modifier les informations d’un utilisateur existant.\n",
        "\t-\t**Usage** : Utilisé pour remplacer entièrement une ressource ou pour mettre à jour certaines de ses propriétés.\n",
        "4.\t**DELETE** 🗑️\n",
        "\t-\t**Description** : Supprime des données du serveur.\n",
        "\t-\t**Exemple** : Supprimer un utilisateur spécifique.\n",
        "\t-\t**Usage** : Utilisé pour enlever des ressources de la base de données.\n",
        "\n",
        " \n",
        "Dans le cadre de ce cours nous n'allons qu'utiliser la méthode **get** pour récupérer des donneés. Mais si tu souhaites t'instruire tu pourras lire cet article (après la master class):\n",
        "- 📚 [Explication des méthodes Rest](https://blog.postman.com/what-are-http-methods/)\n",
        " \n",
        "\n",
        "Dans notre cours nous allons l'utiliser pour récupérer des données et comprendre comment ajouter des paramètre aux besoins.   "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27fddc39",
      "metadata": {},
      "source": [
        "#### Le status code de la réponse api ✅\n",
        "Les codes d’état HTTP sont des nombres à trois chiffres renvoyés par un serveur en réponse à une requête HTTP effectuée par un client. Ils sont classés en différentes catégories selon leur première chiffre, indiquant le type de réponse.\n",
        "\n",
        "-\t1xx 🕒 : Informationnel – Indique que la requête est en cours de traitement.\n",
        "-\t2xx ✅ : Succès – La requête a été traitée avec succès.\n",
        "-\t3xx 🔄 : Redirection – Nécessite une action supplémentaire du client.\n",
        "-\t4xx ❌ : Erreurs du Client – Problème avec la requête envoyée par le client.\n",
        "-\t5xx 🚫 : Erreurs du Serveur – Problème côté serveur lors du traitement de la requête."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b026da8",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "### Un petit éxemple ✍🏽\n",
        "\n",
        "Nous allons prendre un exemple courant ! Imaginons que je souhaites aller récupérer des données sur l'open data de la région réunion (éxemple pris totalement au hasard) 😏\n",
        "\n",
        "\n",
        "- [Lien de l'open data hub de la Région Réunion](https://data.regionreunion.com/explore)\n",
        "\n",
        "\n",
        "\n",
        "<div style=\"text-align: center;\">\n",
        "<img src=\"./image/api.png\" width=\"300\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3); border-radius:10px;\"/>\n",
        "  <figcaption>Explication simpliste d'une API</figcaption>\n",
        "\n",
        "</div>\n",
        "\n",
        "1.\t📤 J’effectue ma requête avec l’URL du bloc précédent et avec la méthode GET.\n",
        "    -\tEnvoyer une demande pour obtenir des données spécifiques.\n",
        "2.\t🖥️ Le serveur réceptionne ma requête et vérifie les paramètres.\n",
        "    -\tLe serveur reçoit la demande et s’assure que toutes les informations nécessaires sont présentes et correctes.\n",
        "3.\t🔍 En fonction des paramètres, il demande à la base de données les informations dont il a besoin.\n",
        "    -\tLe serveur interroge la base de données en fonction des critères spécifiés dans la requête.\n",
        "4.\t📥 Il récupère les données.\n",
        "    -\tLes données demandées sont extraites de la base de données.\n",
        "5.\t🔄 Les retourne à l’utilisateur.\n",
        "\t    -\tLe serveur envoie les données récupérées en réponse à la requête initiale.\n",
        "\n",
        "\n",
        "Avec l'url que nous avons utiliser plus haut qui est la suivante :\n",
        "- [Url de l'api région en get](https://data.regionreunion.com//api/explore/v2.1/catalog/datasets/lieux-remarquables-lareunion-wssoubik/records?limit=20&refine=commune%3A%22Saint-Louis%22)\n",
        "\n",
        "Voici le résultat :\n",
        "<div style=\"text-align: center;\">\n",
        "<img src=\"./image/api-response.png\" width=\"300\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3);border-radius:10px;\"/>\n",
        "  <figcaption>Réponse de l'api open data Région\n",
        "</figcaption>\n",
        "\n",
        "</div>\n",
        "\n",
        "</div>\n",
        "\n",
        "J'ai bien les informations pour la commune de saint louis 🎉 \n",
        "\n",
        "**💥 Quand tu effectue une requête sur ton navigateur c'est un GET qui est effectué**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6eac51bc",
      "metadata": {},
      "source": [
        "Astuce ✌🏼:\n",
        "- Si tu souhaites avoir le json retour formatté dans ton navigateur tu peux installer (plus tard)\n",
        "  - [Basic json formatter pour firefox 🦊](https://addons.mozilla.org/en-US/firefox/addon/basic-json-formatter/)\n",
        "  - [Json formatter pour chrome 🏀](https://chromewebstore.google.com/detail/json-formatter/bcjindcccaagfpapjjmafapmmgkkhgoa?hl=en&pli=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "exemple-requests",
      "metadata": {},
      "source": [
        "### Éxercice 1 : Récupérer des données avec `requests`\n",
        "\n",
        "Normalement avec les prepwork vous avez déja du installer votre environnement python 🫣. Si ce n'est pas le cas installer rapidement requests avec la commande suivande:\n",
        "````\n",
        "pip install requests\n",
        "````\n",
        "**requests** est une bibliothèque Python pour envoyer des requêtes HTTP. Elle simplifie la communication avec des services web et des APIs en permettant aux développeurs d’effectuer facilement des opérations telles que **GET, POST, PUT, DELETE,** et bien d’autres, sans avoir à gérer les détails complexes du protocole HTTP.\n",
        "\n",
        "La première api que tu vas utiliser ici, possède l'url suivante :\n",
        "\n",
        "````\n",
        "url = \"https://dashboard-strapi.hodi.cloud/api/test-w-ts\"\n",
        "````\n",
        "\n",
        "Voici la réponse de l'api:\n",
        "\n",
        "<figure style=\"text-align: center;\">\n",
        "  <img src=\"./image/api-response.png\" width=\"300\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3); border-radius: 10px;\"/>\n",
        "  <figcaption>Exemple de réponse d'une API</figcaption>\n",
        "</figure>\n",
        "\n",
        "\n",
        "<!-- ![Reponse de l'api](./image/api_reponse.png) -->\n",
        "\n",
        "Clic sur ce lien est tu verras la même chose :\n",
        "\n",
        "[Lien de l'api](http://localhost:1337/api/test-w-ts)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2edd6e87",
      "metadata": {},
      "source": [
        "Dans ce premier exercice tu vas:\n",
        "- Importer requests\n",
        "- Définir l'url de l'api \n",
        "- Effectuer ton get avec requests\n",
        "- Convertir la reponse en dictionnaire\n",
        "- Stocker le status et la réponse de l'api dans \n",
        "  - status_code \n",
        "  - api_response_data (⛔️ attention il faut le message de la réponse pour passer le test pas juste le dictionnaire)\n",
        "- Afficher la reponse de l'api qui doit être **\"Accés à l'api ok\"**\n",
        "- Afficher le status de la réponse qui doit être \"**200**\"\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "code-requests",
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "# URL de l'API\n",
        "url = \"https://dashboard-strapi.hodi.cloud/api/test-w-ts\"\n",
        "\n",
        "#J'effectue une requête GET\n",
        "response =\n",
        "\n",
        "# Vérifier le statut de la réponse\n",
        "status_code =\n",
        "# Je récupére la réponse dont j'ai besoin\n",
        "api_response_data =\n",
        "\n",
        "print(\"Le status de la réponse:\", status_code)\n",
        "\n",
        "# Ce dont j'ai besoin\n",
        "print(f\"Ce dont j'ai besoin: \\n  ---- {api_response_data}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abc9f612",
      "metadata": {},
      "source": [
        "Verifie tes résultats avec le test en dessous 🤞🏼:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46968064",
      "metadata": {},
      "outputs": [],
      "source": [
        "import unittest\n",
        "import test_api\n",
        "\n",
        "test_api.status_code = status_code\n",
        "test_api.api_response = api_response_data\n",
        "\n",
        "loader = unittest.TestLoader()\n",
        "suite = loader.loadTestsFromTestCase(test_api.TestApiResponse)\n",
        "\n",
        "runner = unittest.TextTestRunner()\n",
        "result = runner.run(suite)\n",
        "\n",
        "if result.wasSuccessful():\n",
        "    print(\"✅ Tous les tests ont réussi! ✅\")\n",
        "else:\n",
        "    print(\"❌ Échec des tests\")\n",
        "    for failure in result.failures:\n",
        "        print(failure)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31824fda",
      "metadata": {},
      "source": [
        "Si tu n'as ✅ Tous les tests ont réussi! ✅, essai de nouveau !"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9abea3f",
      "metadata": {},
      "source": [
        "### Éxércice 2 : Récupérer et parcourir des données\n",
        "\n",
        "Dans cet exercice, les choses deviennent un petit peu plus compliqués.. Un petit peu **promis** 🤞🏼\n",
        "\n",
        "L'url change pour cet exercice et tu vas utiliser la suivante :\n",
        "\n",
        "````\n",
        "url = https://dashboard-strapi.hodi.cloud/api/articles\n",
        "````\n",
        "\n",
        "Les api utilisent souvent des façon d'envoyer des paramètre de façon différentes. Ce qui est par contre assez commun, c'est d'avoir un **?** qui sépare l'url des paramètres que nous avons vu plus haut (dans le cas d'un get).\n",
        "\n",
        "En gros:\n",
        "- **url**/**?** **params**\n",
        "\n",
        "Dans cet exercice tu vas devoir lister l'ensemble des **titres** et des **id** que retourne l'url que je t'ai donné un peu plus haut. \n",
        "\n",
        "Cette api est generée par STRAPI et possède une documentation simple pour savoir comment donner en paramètres les champs dont j'ai besoin à mon api. \n",
        "- [Documentation de strapi](https://docs.strapi.io/dev-docs/api/rest/populate-select)\n",
        "\n",
        "\n",
        "Astuce 💡:\n",
        "- Check la section **Field Selection**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "004ee306",
      "metadata": {},
      "source": [
        "Ceux que tu vas devoir faire:\n",
        "1. Définir la bonne url \n",
        "2. Effectuer un get avec request\n",
        "3. Convertir la réponse en dictionnaire\n",
        "4. Faire une liste de l'ensemble des id dans la variable id_list\n",
        "5. faire une liste de l'ensemble des titres dans la variable id_titles\n",
        "6. Tester ton code "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47cd7c7d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Définir l'url de l'API\n",
        "url_articles = \"\"\n",
        "\n",
        "# Faire une requête GET\n",
        "response =\n",
        "\n",
        "# Convertir la réponse en dictionnaire\n",
        "data =\n",
        "\n",
        "# Faire une liste avec une list comprehension pour id_list et id_titles\n",
        "id_list=\n",
        "id_titles =\n",
        "print(id_titles)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14301fae",
      "metadata": {},
      "source": [
        "Verifie tes résultats avec le test en dessous 🤞🏼:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76d19649",
      "metadata": {},
      "outputs": [],
      "source": [
        "import test_api_2\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "test_api_2.id_list = id_list\n",
        "test_api_2.id_titles = id_titles\n",
        "\n",
        "loader = unittest.TestLoader()\n",
        "suite = loader.loadTestsFromTestCase(test_api_2.TestArticlesAPI)\n",
        "\n",
        "runner = unittest.TextTestRunner()\n",
        "result = runner.run(suite)\n",
        "\n",
        "if result.wasSuccessful():\n",
        "    display(HTML('''\n",
        "    <div style=\"text-align: center;\">\n",
        "        <img src=\"./image/bravo.jpg\" width=\"300\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3);\"/>\n",
        "    </div>\n",
        "    '''))\n",
        "else:\n",
        "    print(\"❌ Échec des tests\")\n",
        "    for failure in result.failures:\n",
        "        print(failure)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb95fc1d",
      "metadata": {},
      "source": [
        "#### À ce stade, tu gères déjà bien les trucs essentiels du web 🎉:\n",
        "\n",
        "-\tLes méthodes HTTP : Tu sais quand utiliser GET, POST, etc., pour interagir avec une API.\n",
        "-\tLes status codes : Genre le 200, 404, 500… tu sais direct si tout va bien ou si ça plante.\n",
        "-\tLes paramètres d’URL : Tu sais ajouter des filtres dans l’URL pour récupérer juste ce dont tu as besoin.\n",
        "-\tParser un JSON : T’es capable de récupérer des données d’une requête et les organiser en listes ou dicos."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffe9c32f",
      "metadata": {},
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "partie2-scraping",
      "metadata": {},
      "source": [
        "## Partie 2 : Web Scraping avec BeautifulSoup\n",
        "\n",
        "### Qu'est-ce que le Web Scraping ?\n",
        "\n",
        "Le web scraping, c’est l’art d’extraire des infos d’un site web de manière automatisée.\n",
        "\n",
        "Dans la partie précédente, je t’ai donné la grande nouvelle… Toutes les pages web sont accessibles via un simple **GET**.\n",
        "\n",
        "➡️  Mais parfois, les données que tu attends ne sont pas là directement. Au lieu des articles, tu ne récupères que le squelette 🩻 du site. Pourquoi ? Parce que le site fait peut-être appel à une API en arrière-plan qui met du temps à répondre. Résultat : tu te retrouves avec une page vide ou incomplète.\n",
        "\n",
        "Nous n'aurons pas à traiter cet éxemple dans ce cours, mais si tu veux une piste pour régler ce type de problème tu peux te tourner vers **Selenium** pour scraper des sites en python. \n",
        "\n",
        "**En résumé :**\n",
        "\n",
        "-\tSi la page est rendue via JavaScript (comme un site dynamique où les données arrivent après un certain temps), utilise **Selenium**.\n",
        "-\tSi les données sont dans le HTML dès le chargement initial (pas besoin d’attendre du JS), alors **requests** + **BeautifulSoup** suffisent.\n",
        "\n",
        "**BeautifulSoup** 🍲, c’est une bibliothèque Python qui te permet de naviguer et extraire des données facilement à partir de pages HTML ou XML. En gros, elle t’aide à trouver et parser des éléments dans une page web, comme des titres, des liens, des paragraphes, etc.\n",
        "\n",
        "Tu lui donnes le contenu **HTML** d’une page, et elle te permet de chercher rapidement des trucs comme des **balises** , des **classes**, des **ID**, ou d’autres éléments pour les **scraper**.\n",
        "\n",
        "C’est super pratique quand tu utilises requests ou un autre moyen pour récupérer le HTML d’une page et que tu veux **extraire** des infos spécifiques.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "exemple-scraping",
      "metadata": {},
      "source": [
        "### Éxercice 1 : Extraire les titres des articles d'une page web \n",
        "\n",
        "Rendez-vous 👮🏼‍♂️  sur :\n",
        "- [HackerNews](https://news.ycombinator.com/)\n",
        "\n",
        "Vous êtes censé voir un ensemble d'article un peu comme ça:\n",
        "\n",
        "<div style=\"text-align: center;\">\n",
        "<img src=\"./image/hackernews.png\" width=\"500\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3); border-radius: 10px;\"/>\n",
        "  <figcaption>Interface de Hacker News</figcaption>\n",
        "\n",
        "</div>\n",
        "\n",
        "On peut déja identifier une structure qui se répéte plusieurs fois :\n",
        "  - Des titres\n",
        "  - Des auteurs\n",
        "  - des dates \n",
        "  - des sites \n",
        "\n",
        "Dans toutes cette répétition d'article on peut y voir un composant qui revient très souvent ⬇️ ⬇️ ⬇️:\n",
        "<div style=\"text-align: center;\">\n",
        "<img src=\"./image/bloc_h.png\" width=\"500\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3);border-radius: 10px;\"/>\n",
        "  <figcaption>Composant répétitif d'un article sur Hacker News</figcaption>\n",
        "\n",
        "</div>\n",
        "\n",
        "Pour cet exercice, il va falloir **scraper** sur la page d'hacker news 🏴‍☠️:\n",
        "- Chaque titre \n",
        "- Chaque auteurs\n",
        "\n",
        "\n",
        "Mais **JAMY** comment on fait ca ? 🤓\n",
        "\n",
        "<figure style=\"text-align: center;\">\n",
        "  <img src=\"./image/buthow.jpg\" width=\"300\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3); border-radius: 10px;\"/>\n",
        "  \n",
        "</figure>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a702562e",
      "metadata": {},
      "source": [
        "Quand tu vas sur hacker news, que tu fais clic droit et enfin voir le code source:\n",
        "<figure style=\"text-align: center;\">\n",
        "  <img src=\"./image/option.png\" width=\"500\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3); border-radius: 10px;\"/>\n",
        "  <figcaption>Menu contextuel pour accéder au code source</figcaption>\n",
        "</figure>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83b670cd",
      "metadata": {},
      "source": [
        "Tu arrives sur une page du style:\n",
        "\n",
        "<figure style=\"text-align: center;\">\n",
        "  <img src=\"./image/sourhn.png\" width=\"700\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3); border-radius: 10px;\"/>\n",
        "  <figcaption>Aperçu du code source de Hacker News</figcaption>\n",
        "</figure>\n",
        "\n",
        "Tu commence à avoir une idée ?  🧠\n",
        "\n",
        "Le concept est en soit assez simple, tu dois: \n",
        "1. Identifier dans le code source de la page les informations dont tu as besoin \n",
        "2. Faire une request GET sur le site de hacker news\n",
        "3. Parser tes données avec beautifoulsoup > Donc le code html de la page\n",
        "4. Isoler les élèments dont tu as besoin\n",
        "5. Placer dans une liste tous les titres et tous les auteurs\n",
        "\n",
        "\n",
        "**No worries 🕵🏼‍♂️ nous allons le faire ensemble.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "code-scraping",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Importer les lib dont j'ai besoin\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# URL de la page à scraper\n",
        "url = \"https://news.ycombinator.com/\"\n",
        "\n",
        "# Obtenir le contenu de la page\n",
        "response = requests.get(url)\n",
        "\n",
        "# Parser le HTML\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# Trouver tous les titres d'articles avec un find all sur des élèments unique\n",
        "titles = soup.find_all('span', class_='titleline')\n",
        "title_list=[i.text  for i in titles]\n",
        "\n",
        "author = soup.find_all('a', class_='hnuser')\n",
        "author_list=[i.text  for i in author]\n",
        "\n",
        "print(f\"La liste des titres des articles d'hackerNews :\\n{title_list}\\n ainsi que le nombre d'élèments de cette liste: {len(title_list)}\")\n",
        "print(f\"La liste des auteurs des articles d'hackerNews :\\n{author_list}\\n ainsi que le nombre d'élèments de cette liste: {len(author_list)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2851bdf6",
      "metadata": {},
      "source": [
        "**Good 🎉**\n",
        "\n",
        "Mais on a un petit problème... 🤷🏽‍♂️\n",
        "La liste des titres, n'a pas la même longueur que celle des auteurs. (en espérant que cela soit aussi le cas le jour de la masterclass 🥲)\n",
        "Il faut donc améliorer ce script pour que cela soit exploitable peut-être pour une futur api ? \n",
        "Convertissons en dictionnaire nos deux listes précédentes et de façon structurer s'il vous plaît !\n",
        "\n",
        "Le début reste le même ..\n",
        "\n",
        "À l'inverse de tout à l'heure, au lieu de cibler directement les éléments dont j'ai besoin, je vais essayer de trouver une div plus haute dans la hiérarchie qui englobe tout mon composant. Et j'enchaîne par une for loop afin de récupérer le titre et auteur que je placerais dans une liste de dictionnaires !! 🥵"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3940ebd6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# URL de la page à scraper\n",
        "url = \"https://news.ycombinator.com/\"\n",
        "\n",
        "# Obtenir le contenu de la page\n",
        "response = requests.get(url)\n",
        "\n",
        "# Parser le HTML\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# J'identifie le point d'accroche possibe\n",
        "tr_tags =\n",
        "\n",
        "#J'ajoute mes id à ma liste tr_tags_list en effectuant le get je récupére l'id de mon tag tr\n",
        "tr_tags_list =\n",
        "\n",
        "# tr_title = soup.find('tr', id='41614949').find('span', class_='titleline').find('a').string\n",
        "# tr_auteur = soup.find('span', id='score_41614949').find_parent('span', class_='subline').find('a',class_=\"hnuser\").string\n",
        "\n",
        "#Fonction lambda pour obtenir le titre et l'auteur\n",
        "get_tr_title =\n",
        "\n",
        "#Fonction lambda pour obtenir l'auteur\n",
        "get_tr_auteur =\n",
        "\n",
        "final_dict = [{ \"id\": key, \"title\": get_tr_title(key), \"author\": get_tr_auteur(key)} for key in tr_tags_list]\n",
        "print(final_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90a02006",
      "metadata": {},
      "source": [
        "Ok, nous allons y aller doucement. 🐢\n",
        "Je vais t'éxpliquer en détail comment ca fonctionne. \n",
        "\n",
        "Premièrement, dans le code source je remarque que je ne peux pas boucler sur une balise avec un **find_all**.\n",
        "\n",
        "Le find_all va me **grouper** tous ceux qu'il va trouver avec les conditions que je lui ai donné ici :\n",
        "- Les balises ```tr```\n",
        "- Qui ont  une balise enfant ```span``` qui possède la classe ```subline```\n",
        "\n",
        "Si cette condition n'est pas réspécté le ```tr``` n'est pas dans ma liste retour. \n",
        "\n",
        "Mon titre et mon auteur sont dans deux balises séparées ... C'est embétant. \n",
        "Nous le voyons bien dans l'image suivante:\n",
        "<div style=\"text-align: center;\">\n",
        "<img src=\"./image/group.png\" width=\"700\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3);border-radius: 10px;\"/>\n",
        "  <figcaption>Composant répétitif d'un article sur Hacker News</figcaption>\n",
        "</div>\n",
        "\n",
        "Il faut donc trouver une solution. \n",
        "Pour ce faire on remarque ca dans le code source: \n",
        "<div style=\"text-align: center;\">\n",
        "<img src=\"./image/reflexion.png\" width=\"700\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3);border-radius: 10px;\"/>\n",
        "  <figcaption>ID répétitif d'un article sur Hacker News</figcaption>\n",
        "</div>\n",
        "\n",
        "Il y a donc bien toujours une **solution** 🎉 \n",
        "\n",
        "Pour récupérer le titre voila ce que je fais dans cette lambda function:\n",
        "\n",
        "````python \n",
        "soup.find('tr', id=id).find('span', class_='titleline').find('a').string\n",
        "````\n",
        "C'est mieux éxpliqué en image: \n",
        "<div style=\"text-align: center;\">\n",
        "<img src=\"./image/firstsoup.png\" width=\"700\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3);border-radius: 10px;\"/>\n",
        "  <figcaption>Première étape de notre lambda function</figcaption>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "explication-scraping",
      "metadata": {},
      "source": [
        "Pour le deuxième bloc c'est un tout petit peu plus tricky:\n",
        "````python\n",
        "soup.find('span', id=f'score_{id}').find_parent('span', class_='subline').find('a', class_=\"hnuser\").string\n",
        "````\n",
        "<div style=\"text-align: center;\">\n",
        "<img src=\"./image/groupsoup2.png\" width=\"700\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3); border-radius: 10px;\"/>\n",
        "  <figcaption>Deuxième étape de notre lambda function</figcaption>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "conclusion",
      "metadata": {},
      "source": [
        "**Well done !! 👌🏼\n",
        "Maintenant c'est à vous de jouer dans l'éxercice 2!**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d88d4db",
      "metadata": {},
      "source": [
        "### Éxercice 2 : À votre tour de scraper !!! ⭐️\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1a1301d",
      "metadata": {},
      "source": [
        "Dans le cadre de cet masterClass, on vous mets gracieusement à disposition un site test de scraping 🎉: \n",
        "- [Site Scraping masterclass 1](https://masterclasdatasscraping.hodi.cloud/)\n",
        "\n",
        "Le but de cet exercice va être le suivant, tu dois avoir exactement les mêmes resultats que cette requête api:\n",
        "\n",
        "````python\n",
        "url_articles = \"https://dashboard-strapi.hodi.cloud/api/articles?fields[0]=id&fields[1]=title&fields[2]=body\"\n",
        "````\n",
        "Qui ressemble à cela:\n",
        "<div style=\"text-align: center;\">\n",
        "<img src=\"./image/newrequeststrapi.png\" width=\"900\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3);border-radius: 10px;\"/>\n",
        "  <figcaption>Requête API de notre exercice</figcaption>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "751a5c4c",
      "metadata": {},
      "source": [
        "Sur le site tu vas avoir une architecture comme celle la:\n",
        "\n",
        "1. Pour la liste des articles\n",
        "<div style=\"text-align: center;\">\n",
        "<img src=\"./image/whatiwant1.png\" width=\"700\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3);border-radius: 10px;\"/>\n",
        "  <figcaption>Le site à scraper</figcaption>\n",
        "</div>\n",
        "\n",
        "2. Pour le corp des articles (le body)\n",
        "<div style=\"text-align: center;\">\n",
        "<img src=\"./image/whatiwant2.png\" width=\"700\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3);border-radius: 10px;\"/>\n",
        "  <figcaption>Un article du site</figcaption>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cc6dee8",
      "metadata": {},
      "source": [
        "Il y à deux petits **pièges** 😬:\n",
        "- Le site à une pagination, promis je ne l'ai pas fait éxprès 🤞🏼\n",
        "- Le body des article se trouve à une autre URL que celle de la page d'acceuil 😇\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93cc1aaa",
      "metadata": {},
      "source": [
        "**Comment te lancer dans cet exercice ? 🚀**\n",
        "1.\tAnalyse bien les données du JSON que tu obtiens avec la requête vers url de l’API précédente. 🧐\n",
        "2.\tRegarde l’URL de la page d’accueil du site et observe comment fonctionne la pagination. Est-ce que l’URL change ou pas ? 🔄\n",
        "3.\tVérifie la page article : de quoi est-elle composée ? Est-ce que j’ai des informations sur la page d’accueil qui me permettent d’accéder directement à la page article ? 🔗\n",
        "4. Est-ce que je peux scraper tout le site avec un simple GET ? ❓ (👉 NON ❗)\n",
        "5. Combien de page j'ai ??? 🙄"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fef1ecc",
      "metadata": {},
      "source": [
        "🎯 Ton objectif : créer une liste de dictionnaires où chaque objet contiendra les champs suivants (bien remplis, bien sûr) :\n",
        "\n",
        "```python\n",
        "scrap_site_data = [\n",
        "  {\"id\": 1, \n",
        "  \"title\": \"Un titre random\", \n",
        "  \"body\": \"Un body random\"},\n",
        "  # etc...\n",
        "]\n",
        "```\n",
        "\n",
        "📋 Pour chaque élément, assure-toi d’inclure :\n",
        "\n",
        "-\tid : l’identifiant unique de l’objet\n",
        "-\ttitle : le titre de l’article ou de la section\n",
        "-\tbody : le contenu ou un résumé de l’article\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c603d937",
      "metadata": {},
      "source": [
        "🚀 Laisse-moi te filer un coup de pouce :\n",
        "\n",
        "-\tL’URL d’un article ressemble à ça : ```/article/{id}```\n",
        "-\tPour naviguer entre les pages, tu dois simplement ajouter ce paramètre à l’URL : ```?page={pageNumber}```.\n",
        "-\tPour trouver l’id… je te laisse fouiller un peu ! 🔍😉 Peut-être dans le code source de la page ? I dont know 🤷🏽‍♂️\n",
        "\n",
        "\n",
        "Voila la checklist qu'on doit valider:\n",
        "- ⬜️ Connaître le nombre de pages de façon programmatique\n",
        "- ⬜️ Scraper le nombre de pages disponibles\n",
        "- ⬜️ Accéder à chaque page pour scraper le body d'un article\n",
        "\n",
        "<div style=\"text-align: center;\">\n",
        "<img src=\"./image/justdoit.jpg\" width=\"400\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3); border-radius: 10px;\"/>\n",
        "  <figcaption>Jimmy neutron fait un haka</figcaption>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d03be90",
      "metadata": {},
      "source": [
        "##### Étape 1 - Récupère le nombre de page 📖"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45b85fb6",
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "urlToGet='https://masterclasdatasscraping.hodi.cloud/'\n",
        "#Je récupère la home page de mon site\n",
        "website = requests.get(urlToGet)\n",
        "\n",
        "#Je le parse avec Bs4\n",
        "soup = BeautifulSoup(website.text, 'html.parser')\n",
        "#Maintenant voyons voir combien de page j'ai\n",
        "pages =\n",
        "nbPages=\n",
        "print(f\"Nombre de page: {nbPages}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c2d55dc",
      "metadata": {},
      "source": [
        "Dans le code source 💾 de cette page voila ce que je remarque:\n",
        "<div style=\"text-align: center;\">\n",
        "<img src=\"./image/pagination.png\" width=\"700\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3); border-radius: 10px;\"/>\n",
        "  <figcaption>Pagination du site</figcaption>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9882e48c",
      "metadata": {},
      "source": [
        "Mais le **gTxG4** ou encore le **ro1Hj** me fait un peu peur 😱. Du coup, je pense qu’il y a de fortes chances que Home_pagination reste fixe, mais que cet ID mystérieux, probablement généré dynamiquement par la technologie du site, change régulièrement.\n",
        " \n",
        "C’est pour cela que j’utilise cette commande :\n",
        "```python\n",
        "pages = soup.find_all('a', class_=re.compile(r'^Home_pagination'))\n",
        "```\n",
        "\n",
        "Elle demande de chercher la balise ```a``` qui contient une classe commençant par ```Home_pagination```. J’utilise une expression régulière pour m’assurer que cette donnée est bien présente : le symbole ```^``` signifie “**commence par**”.\n",
        "\n",
        "➡️➡️➡️  [Si vous voulez en apprendre plus sur les éxpressions régulieres](https://www.rexegg.com/regex-quickstart.php)  ⬅️⬅️⬅️\n",
        "\n",
        "Notre checklist : \n",
        "- ✅ Connaître le nombre de pages de façon programmatique\n",
        "- ⬜️ Scraper le nombre de pages disponibles\n",
        "- ⬜️ Accéder à chaque page pour scraper le body d'un article\n",
        "\n",
        "Et maintenant, en route pour le grand scrapathon sur le nombre de pages défini plus haut ! 🎉🚀\n",
        "\n",
        "##### Étape 2 - Scraper les n pages et ... accéder à chaque page ...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "840eed5a",
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "urlToGet='https://masterclasdatasscraping.hodi.cloud/'\n",
        "\n",
        "get_article_body =\n",
        "get_article_title =\n",
        "\n",
        "listResult = []\n",
        "\n",
        "\n",
        "print(listResult)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "973eb237",
      "metadata": {},
      "source": [
        "**Notre checklist 🎉:**\n",
        "- ✅ Connaître le nombre de pages de façon programmatique\n",
        "- ✅ Scraper le nombre de pages disponibles\n",
        "- ✅ Accéder à chaque page pour scraper le body d'un article\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f952657",
      "metadata": {},
      "source": [
        "<div style=\"text-align: center;\">\n",
        "<iframe src=\"https://giphy.com/embed/d3mlE7uhX8KFgEmY\" width=\"480\" height=\"269\" style=\"\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe>\n",
        "<p><a href=\"https://giphy.com/gifs/culture--think-hmm-d3mlE7uhX8KFgEmY\"></a></p>\n",
        "<figcaption>Bien joué à tous</figcaption>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67591b36",
      "metadata": {},
      "source": [
        "## Conclusion : Ce que vous avez appris aujourd'hui ! 🎓🚀\n",
        "\n",
        "1. Les API, c'est la vie ! 🌐\n",
        "   - Méthodes HTTP (GET, POST, etc.) 📡\n",
        "   - Status codes (200 OK, 404 Not Found, etc.) 🚦\n",
        "   - Paramètres d'URL pour filtrer les données 🔍\n",
        "\n",
        "2. Requests, votre nouveau meilleur ami 🤝\n",
        "   - Faire des requêtes HTTP en Python 🐍\n",
        "   - Récupérer et traiter les réponses JSON 📊\n",
        "\n",
        "3. Web Scraping avec BeautifulSoup 🍲\n",
        "   - Extraire des données de pages HTML 🕷️\n",
        "   - Naviguer dans la structure d'une page web 🧭\n",
        "\n",
        "4. Techniques avancées de scraping 🥷\n",
        "   - Gérer la pagination 📄\n",
        "   - Extraire des données de plusieurs pages 📚\n",
        "   - Construire des datasets structurés 🏗️\n",
        "\n",
        "5. Bonnes pratiques et astuces 💡\n",
        "   - Utiliser les expressions régulières 🔬\n",
        "   - Optimiser vos scripts de scraping ⚡\n",
        "\n",
        "Vous êtes maintenant prêts à conquérir le monde des données web ! 🌍💪\n",
        "N'oubliez pas : avec un grand pouvoir viennent de grandes responsabilités. Scrapez éthiquement ! 🦸‍♂️🦸‍♀️"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8755895b",
      "metadata": {},
      "source": [
        "## Mémo des ressources 📚🔗\n",
        "\n",
        "Voici un récapitulatif de toutes les ressources et URLs utiles mentionnées dans ce cours :\n",
        "\n",
        "### APIs et Documentation 🌐\n",
        "\n",
        "- [Documentation de Strapi](https://docs.strapi.io/dev-docs/api/rest/populate-select)\n",
        "  Pour comprendre comment utiliser les paramètres dans les requêtes API Strapi.\n",
        "\n",
        "- [Open Data Hub de la Région Réunion](https://data.regionreunion.com/explore)\n",
        "  Exemple d'API publique .\n",
        "\n",
        "### Outils de développement 🛠️\n",
        "\n",
        "- [Basic JSON Formatter pour Firefox](https://addons.mozilla.org/en-US/firefox/addon/basic-json-formatter/)\n",
        "- [JSON Formatter pour Chrome](https://chromewebstore.google.com/detail/json-formatter/bcjindcccaagfpapjjmafapmmgkkhgoa)\n",
        " \n",
        "\n",
        "### Sites pour pratiquer le scraping 🕷️\n",
        "\n",
        "- [Hacker News](https://news.ycombinator.com/)\n",
        "  Site utilisé pour les exercices de scraping.\n",
        "\n",
        "- [Site de scraping MasterClass](http://localhost:3000)\n",
        "  Site spécialement conçu pour pratiquer vos compétences en scraping.\n",
        "\n",
        "### Ressources d'apprentissage supplémentaires 📖\n",
        "\n",
        "- [Explication des méthodes REST](https://blog.postman.com/what-are-http-methods/)\n",
        "  Pour approfondir votre compréhension des méthodes HTTP.\n",
        "\n",
        "- [Guide rapide des expressions régulières](https://www.rexegg.com/regex-quickstart.php)\n",
        "  Pour maîtriser les regex utilisées dans le scraping avancé.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
