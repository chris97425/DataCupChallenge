{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "introduction",
      "metadata": {},
      "source": [
        "# Chapitre 1 👌🏼 : Introduction aux API et au Web Scraping 🕸️\n",
        "\n",
        "\n",
        "Dans ce cours, nous allons explorer comment interagir avec des API et comment effectuer du web scraping en Python.\n",
        "\n",
        "Tu vas voir comment utiliser requests et beautifoul soup ✅\n",
        "\n",
        "Si tu as la moindre question 🙌🏼 n'hésite pas.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "partie1-api",
      "metadata": {},
      "source": [
        "## Utilisation des API\n",
        "\n",
        "### Une API KESAKO 🫢 ?\n",
        "\n",
        "Une api de façon generale, c'est un bloc qui vous permet d'échanger des données entres deux types de services. \n",
        "\n",
        "Vous voulez faire le lien entre une base de données 💽 et une application mobile 📱 BAMM 💥 >> API\n",
        "\n",
        "En gros, vous la questionnez et elle vous renvoie un truc.\n",
        "\n",
        "Dans les faits c'est assez simple 😲:\n",
        "\n",
        "1. Une action de quelque chose ou de quelqu'un envoie des informations à l'api \n",
        "2. L'api récupère les infos les traitent (à ce moment, elle peut contacter une base de données, ou d'autres services)\n",
        "3. L'api (de façon général) renvoie quelque chose qui peut être lu du côtés de l'utilisateur\n",
        "\n",
        "Une api peut être utilisée pour effectuer, beaucoup, beaucoup, beaucoup de chose 🥵. En fonction des actions que nous allons lui demander de faire il convient d'utiliser la bonne méthode http.\n",
        "\n",
        "Pour utiliser une api, il faut de façon general :\n",
        "1. Utiliser une méthode **REST** (GET,POST ...)\n",
        "2. Avoir une **url**\n",
        "3. Accessoirement avec des paramètres\n",
        "\n",
        "<div style=\"text-align: center;\">\n",
        "<img src=\"./image/composeapi.png\" width=\"500\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3);border-radius: 10px;\"/>\n",
        "  <figcaption>Schéma URL</figcaption>\n",
        "\n",
        "</div>\n",
        "\n",
        "✅ De façon général, la réponse d'une api est dans le format Json. Qui est le plus souvent utilisé dans les retours d'api. Mais tu peux aussi avoir de l'xml ou autre format.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7ede9d0",
      "metadata": {},
      "source": [
        "#### 📡 Les 4 Méthodes Principales d’une API REST\n",
        "\n",
        "1.\t**GET** 📥\n",
        "\t- **Description** : Récupère des données depuis le serveur.\n",
        "  \n",
        "\t-\t**Exemple** : Obtenir la liste des utilisateurs.\n",
        "\t-\t**Usage** : Utilisé pour lire ou consulter des ressources sans les modifier.\n",
        "2.\t**POST** 📨\n",
        "\t-\t**Description** : Envoie de nouvelles données au serveur pour créer une ressource.\n",
        "\t-\t**Exemple** : Ajouter un nouvel utilisateur.\n",
        "\t-\t**Usage** : Utilisé pour créer de nouvelles entrées dans la base de données.\n",
        "3.\t**PUT** 🔄\n",
        "\t-\t**Description** : Met à jour des données existantes sur le serveur.\n",
        "\t-\t**Exemple** : Modifier les informations d’un utilisateur existant.\n",
        "\t-\t**Usage** : Utilisé pour remplacer entièrement une ressource ou pour mettre à jour certaines de ses propriétés.\n",
        "4.\t**DELETE** 🗑️\n",
        "\t-\t**Description** : Supprime des données du serveur.\n",
        "\t-\t**Exemple** : Supprimer un utilisateur spécifique.\n",
        "\t-\t**Usage** : Utilisé pour enlever des ressources de la base de données.\n",
        "\n",
        " \n",
        "Dans le cadre de ce cours nous n'allons qu'utiliser la méthode **get** pour récupérer des donneés. Mais si tu souhaites t'instruire tu pourras lire cet article (après la master class):\n",
        "- 📚 [Explication des méthodes Rest](https://blog.postman.com/what-are-http-methods/)\n",
        " \n",
        "\n",
        "Dans notre cours nous allons l'utiliser pour récupérer des données et comprendre comment ajouter des paramètre aux besoins.   "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27fddc39",
      "metadata": {},
      "source": [
        "#### Le status code de la réponse api ✅\n",
        "Les codes d’état HTTP sont des nombres à trois chiffres renvoyés par un serveur en réponse à une requête HTTP effectuée par un client. Ils sont classés en différentes catégories selon leur première chiffre, indiquant le type de réponse.\n",
        "\n",
        "-\t1xx 🕒 : Informationnel – Indique que la requête est en cours de traitement.\n",
        "-\t2xx ✅ : Succès – La requête a été traitée avec succès.\n",
        "-\t3xx 🔄 : Redirection – Nécessite une action supplémentaire du client.\n",
        "-\t4xx ❌ : Erreurs du Client – Problème avec la requête envoyée par le client.\n",
        "-\t5xx 🚫 : Erreurs du Serveur – Problème côté serveur lors du traitement de la requête."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b026da8",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "### Un petit éxemple ✍🏽\n",
        "\n",
        "Nous allons prendre un exemple courant ! Imaginons que je souhaites aller récupérer des données sur l'open data de la région réunion (éxemple pris totalement au hasard) 😏\n",
        "\n",
        "\n",
        "- [Lien de l'open data hub de la Région Réunion](https://data.regionreunion.com/explore)\n",
        "\n",
        "\n",
        "\n",
        "<div style=\"text-align: center;\">\n",
        "<img src=\"./image/api.png\" width=\"300\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3); border-radius:10px;\"/>\n",
        "  <figcaption>Explication simpliste d'une API</figcaption>\n",
        "\n",
        "</div>\n",
        "\n",
        "1.\t📤 J’effectue ma requête avec l’URL du bloc précédent et avec la méthode GET.\n",
        "    -\tEnvoyer une demande pour obtenir des données spécifiques.\n",
        "2.\t🖥️ Le serveur réceptionne ma requête et vérifie les paramètres.\n",
        "    -\tLe serveur reçoit la demande et s’assure que toutes les informations nécessaires sont présentes et correctes.\n",
        "3.\t🔍 En fonction des paramètres, il demande à la base de données les informations dont il a besoin.\n",
        "    -\tLe serveur interroge la base de données en fonction des critères spécifiés dans la requête.\n",
        "4.\t📥 Il récupère les données.\n",
        "    -\tLes données demandées sont extraites de la base de données.\n",
        "5.\t🔄 Les retourne à l’utilisateur.\n",
        "\t    -\tLe serveur envoie les données récupérées en réponse à la requête initiale.\n",
        "\n",
        "\n",
        "Avec l'url que nous avons utiliser plus haut qui est la suivante :\n",
        "- [Url de l'api région en get](https://data.regionreunion.com//api/explore/v2.1/catalog/datasets/lieux-remarquables-lareunion-wssoubik/records?limit=20&refine=commune%3A%22Saint-Louis%22)\n",
        "\n",
        "Voici le résultat :\n",
        "<div style=\"text-align: center;\">\n",
        "<img src=\"./image/api-response.png\" width=\"300\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3);border-radius:10px;\"/>\n",
        "  <figcaption>Réponse de l'api open data Région\n",
        "</figcaption>\n",
        "\n",
        "</div>\n",
        "\n",
        "</div>\n",
        "\n",
        "J'ai bien les informations pour la commune de saint louis 🎉 \n",
        "\n",
        "**💥 Quand tu effectue une requête sur ton navigateur c'est un GET qui est effectué**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6eac51bc",
      "metadata": {},
      "source": [
        "Astuce ✌🏼:\n",
        "- Si tu souhaites avoir le json retour formatté dans ton navigateur tu peux installer (plus tard)\n",
        "  - [Basic json formatter pour firefox 🦊](https://addons.mozilla.org/en-US/firefox/addon/basic-json-formatter/)\n",
        "  - [Json formatter pour chrome 🏀](https://chromewebstore.google.com/detail/json-formatter/bcjindcccaagfpapjjmafapmmgkkhgoa?hl=en&pli=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "exemple-requests",
      "metadata": {},
      "source": [
        "### Éxercice 1 : Récupérer des données avec `requests`\n",
        "\n",
        "Normalement avec les prepwork vous avez déja du installer votre environnement python 🫣. Si ce n'est pas le cas installer rapidement requests avec la commande suivande:\n",
        "````\n",
        "pip install requests\n",
        "````\n",
        "**requests** est une bibliothèque Python pour envoyer des requêtes HTTP. Elle simplifie la communication avec des services web et des APIs en permettant aux développeurs d’effectuer facilement des opérations telles que **GET, POST, PUT, DELETE,** et bien d’autres, sans avoir à gérer les détails complexes du protocole HTTP.\n",
        "\n",
        "La première api que tu vas utiliser ici, possède l'url suivante :\n",
        "\n",
        "````\n",
        "url = \"https://dashboard-strapi.hodi.cloud/api/test-w-ts\"\n",
        "````\n",
        "\n",
        "Voici la réponse de l'api:\n",
        "\n",
        "<figure style=\"text-align: center;\">\n",
        "  <img src=\"./image/api-response.png\" width=\"300\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3); border-radius: 10px;\"/>\n",
        "  <figcaption>Exemple de réponse d'une API</figcaption>\n",
        "</figure>\n",
        "\n",
        "\n",
        "<!-- ![Reponse de l'api](./image/api_reponse.png) -->\n",
        "\n",
        "Clic sur ce lien est tu verras la même chose :\n",
        "\n",
        "[Lien de l'api](http://localhost:1337/api/test-w-ts)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2edd6e87",
      "metadata": {},
      "source": [
        "Dans ce premier exercice tu vas:\n",
        "- Importer requests\n",
        "- Définir l'url de l'api \n",
        "- Effectuer ton get avec requests\n",
        "- Convertir la reponse en dictionnaire\n",
        "- Stocker le status et la réponse de l'api dans \n",
        "  - status_code \n",
        "  - api_response_data (⛔️ attention il faut le message de la réponse pour passer le test pas juste le dictionnaire)\n",
        "- Afficher la reponse de l'api qui doit être **\"Accés à l'api ok\"**\n",
        "- Afficher le status de la réponse qui doit être \"**200**\"\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c743ee12",
      "metadata": {},
      "source": [
        "<figure style=\"text-align: center;\">\n",
        "  <img src=\"./image/resok.png\" width=\"300\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3); border-radius: 10px;\"/>\n",
        "  <figcaption>Exemple de réponse d'une API</figcaption>\n",
        "</figure>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c5e9290d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"data\": [\n",
            "    {\n",
            "      \"id\": 1,\n",
            "      \"attributes\": {\n",
            "        \"response\": \"Acc\\u00e9s \\u00e0 l'api ok \",\n",
            "        \"createdAt\": \"2024-09-22T04:53:04.631Z\",\n",
            "        \"updatedAt\": \"2024-09-22T04:53:08.525Z\",\n",
            "        \"publishedAt\": \"2024-09-22T04:53:08.524Z\"\n",
            "      }\n",
            "    }\n",
            "  ],\n",
            "  \"meta\": {\n",
            "    \"pagination\": {\n",
            "      \"page\": 1,\n",
            "      \"pageSize\": 25,\n",
            "      \"pageCount\": 1,\n",
            "      \"total\": 1\n",
            "    }\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# On importe la bibliothèque 'requests' qui nous permet de faire des requêtes HTTP\n",
        "import requests\n",
        "import json\n",
        "# On définit l'URL de l'API que nous allons interroger\n",
        "url = \"https://dashboard-strapi.hodi.cloud/api/test-w-ts\"\n",
        "\n",
        "# On fait une requête GET à l'URL spécifiée et on stocke la réponse dans 'monRetourApi'\n",
        "monRetourApi = requests.get(url)\n",
        "\n",
        "# On convertit la réponse de l'API (qui est en format JSON) en un dictionnaire Python\n",
        "monDictionnaire = monRetourApi.json()\n",
        "\n",
        "# J'affiche mon dictionnaire\n",
        "print(json.dumps(monDictionnaire, indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "code-requests",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Le status de la réponse: 200\n",
            "Ce dont j'ai besoin: \n",
            "  ---- Accés à l'api ok \n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# On définit l'URL de l'API que nous allons interroger\n",
        "url = \"https://dashboard-strapi.hodi.cloud/api/test-w-ts\"\n",
        "\n",
        "# On fait une requête GET à l'URL spécifiée et on stocke la réponse dans 'response'\n",
        "response  = requests.get(url)\n",
        "\n",
        "# On stock le status code de la réponse\n",
        "status_code = response.status_code\n",
        "\n",
        "#Je converti la réponse en dictionnaire et récupére la donnée dont j'ai besoin\n",
        "api_response_data = response.json().get(\"data\", [{}])[0].get(\"attributes\", {}).get(\"response\", \"Aucune réponse\")\n",
        "\n",
        "# J'affiche le status code\n",
        "print(\"Le status de la réponse:\", status_code)\n",
        "\n",
        "# J'affiche la réponse dont j'ai besoin\n",
        "print(f\"Ce dont j'ai besoin: \\n  ---- {api_response_data}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abc9f612",
      "metadata": {},
      "source": [
        "Verifie tes résultats avec le test en dessous 🤞🏼:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "46968064",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "..\n",
            "----------------------------------------------------------------------\n",
            "Ran 2 tests in 0.002s\n",
            "\n",
            "OK\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Tous les tests ont réussi! ✅\n"
          ]
        }
      ],
      "source": [
        "import unittest\n",
        "import test_api\n",
        "\n",
        "test_api.status_code = status_code\n",
        "test_api.api_response = api_response_data\n",
        "\n",
        "loader = unittest.TestLoader()\n",
        "suite = loader.loadTestsFromTestCase(test_api.TestApiResponse)\n",
        "\n",
        "runner = unittest.TextTestRunner()\n",
        "result = runner.run(suite)\n",
        "\n",
        "if result.wasSuccessful():\n",
        "    print(\"✅ Tous les tests ont réussi! ✅\")\n",
        "else:\n",
        "    print(\"❌ Échec des tests\")\n",
        "    for failure in result.failures:\n",
        "        print(failure)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31824fda",
      "metadata": {},
      "source": [
        "Si tu n'as ✅ Tous les tests ont réussi! ✅, essai de nouveau !"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9abea3f",
      "metadata": {},
      "source": [
        "### Éxércice 2 : Récupérer et parcourir des données\n",
        "\n",
        "Dans cet exercice, les choses deviennent un petit peu plus compliqués.. Un petit peu **promis** 🤞🏼\n",
        "\n",
        "L'url change pour cet exercice et tu vas utiliser la suivante :\n",
        "\n",
        "````\n",
        "url = https://dashboard-strapi.hodi.cloud/api/articles\n",
        "````\n",
        "\n",
        "Les api utilisent souvent des façon d'envoyer des paramètre de façon différentes. Ce qui est par contre assez commun, c'est d'avoir un **?** qui sépare l'url des paramètres que nous avons vu plus haut (dans le cas d'un get).\n",
        "\n",
        "En gros:\n",
        "- **url**/**?** **params**\n",
        "\n",
        "Dans cet exercice tu vas devoir lister l'ensemble des **titres** et des **id** que retourne l'url que je t'ai donné un peu plus haut. \n",
        "\n",
        "Cette api est generée par STRAPI et possède une documentation simple pour savoir comment donner en paramètres les champs dont j'ai besoin à mon api. \n",
        "- [Documentation de strapi](https://docs.strapi.io/dev-docs/api/rest/populate-select)\n",
        "\n",
        "\n",
        "Astuce 💡:\n",
        "- Check la section **Field Selection**\n",
        "- Utilise une liste comprehension pour récupérer les id et les titres [Lien d'explication](https://www.w3schools.com/python/python_lists_comprehension.asp)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "004ee306",
      "metadata": {},
      "source": [
        "Ceux que tu vas devoir faire:\n",
        "1. Définir la bonne url \n",
        "2. Effectuer un get avec request\n",
        "3. Convertir la réponse en dictionnaire\n",
        "4. Faire une liste de l'ensemble des id dans la variable id_list\n",
        "5. faire une liste de l'ensemble des titres dans la variable id_titles\n",
        "6. Tester ton code "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "47cd7c7d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"data\": [\n",
            "    {\n",
            "      \"id\": 2,\n",
            "      \"attributes\": {\n",
            "        \"title\": \"Comment jongler avec des baguettes magiques\"\n",
            "      }\n",
            "    },\n",
            "    {\n",
            "      \"id\": 3,\n",
            "      \"attributes\": {\n",
            "        \"title\": \"Le guide ultime du sabre laser\"\n",
            "      }\n",
            "    },\n",
            "    {\n",
            "      \"id\": 4,\n",
            "      \"attributes\": {\n",
            "        \"title\": \"Le secret du sourire de la Joconde\"\n",
            "      }\n",
            "    },\n",
            "    {\n",
            "      \"id\": 5,\n",
            "      \"attributes\": {\n",
            "        \"title\": \"Comment survivre \\u00e0 une apocalypse zombie\"\n",
            "      }\n",
            "    },\n",
            "    {\n",
            "      \"id\": 6,\n",
            "      \"attributes\": {\n",
            "        \"title\": \"Construire son armure en cave\"\n",
            "      }\n",
            "    },\n",
            "    {\n",
            "      \"id\": 7,\n",
            "      \"attributes\": {\n",
            "        \"title\": \"Les meilleures pizzas pour tortues ninja\"\n",
            "      }\n",
            "    },\n",
            "    {\n",
            "      \"id\": 8,\n",
            "      \"attributes\": {\n",
            "        \"title\": \"Faire ses courses en Batmobile\"\n",
            "      }\n",
            "    },\n",
            "    {\n",
            "      \"id\": 9,\n",
            "      \"attributes\": {\n",
            "        \"title\": \"L'art du camouflage en for\\u00eat\"\n",
            "      }\n",
            "    },\n",
            "    {\n",
            "      \"id\": 10,\n",
            "      \"attributes\": {\n",
            "        \"title\": \"Les vertus du miel magique\"\n",
            "      }\n",
            "    },\n",
            "    {\n",
            "      \"id\": 11,\n",
            "      \"attributes\": {\n",
            "        \"title\": \"Pourquoi les aliens adorent les v\\u00e9los\"\n",
            "      }\n",
            "    },\n",
            "    {\n",
            "      \"id\": 12,\n",
            "      \"attributes\": {\n",
            "        \"title\": \"Article de la masterclass\"\n",
            "      }\n",
            "    }\n",
            "  ],\n",
            "  \"meta\": {\n",
            "    \"pagination\": {\n",
            "      \"page\": 1,\n",
            "      \"pageSize\": 25,\n",
            "      \"pageCount\": 1,\n",
            "      \"total\": 11\n",
            "    }\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Définir l'url de l'API\n",
        "url_articles = \"https://dashboard-strapi.hodi.cloud/api/articles?fields[0]=id&fields[1]=title\"\n",
        "\n",
        "# Faire une requête GET\n",
        "response = requests.get(url_articles)\n",
        "\n",
        "# Convertir la réponse en dictionnaire\n",
        "data = response.json()\n",
        "\n",
        "\n",
        "\n",
        "# Faire une liste avec une list comprehension pour id_list et id_titles\n",
        "id_titles= [dict[\"attributes\"][\"title\"] for dict in data[\"data\"]]\n",
        "id_list= [Dicttttt[\"id\"] for Dicttttt in data[\"data\"]]\n",
        "\n",
        "print(json.dumps(data, indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14301fae",
      "metadata": {},
      "source": [
        "Verifie tes résultats avec le test en dessous 🤞🏼:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "76d19649",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "..\n",
            "----------------------------------------------------------------------\n",
            "Ran 2 tests in 0.002s\n",
            "\n",
            "OK\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div style=\"text-align: center;\">\n",
              "        <img src=\"./image/bravo.jpg\" width=\"300\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3);\"/>\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import test_api_2\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "test_api_2.id_list = id_list\n",
        "test_api_2.id_titles = id_titles\n",
        "\n",
        "loader = unittest.TestLoader()\n",
        "suite = loader.loadTestsFromTestCase(test_api_2.TestArticlesAPI)\n",
        "\n",
        "runner = unittest.TextTestRunner()\n",
        "result = runner.run(suite)\n",
        "\n",
        "if result.wasSuccessful():\n",
        "    display(HTML('''\n",
        "    <div style=\"text-align: center;\">\n",
        "        <img src=\"./image/bravo.jpg\" width=\"300\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3);\"/>\n",
        "    </div>\n",
        "    '''))\n",
        "else:\n",
        "    print(\"❌ Échec des tests\")\n",
        "    for failure in result.failures:\n",
        "        print(failure)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb95fc1d",
      "metadata": {},
      "source": [
        "#### À ce stade, tu gères déjà bien les trucs essentiels du web 🎉:\n",
        "\n",
        "-\tLes méthodes HTTP : Tu sais quand utiliser GET, POST, etc., pour interagir avec une API.\n",
        "-\tLes status codes : Genre le 200, 404, 500… tu sais direct si tout va bien ou si ça plante.\n",
        "-\tLes paramètres d’URL : Tu sais ajouter des filtres dans l’URL pour récupérer juste ce dont tu as besoin.\n",
        "-\tParser un JSON : T’es capable de récupérer des données d’une requête et les organiser en listes ou dicos."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffe9c32f",
      "metadata": {},
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "partie2-scraping",
      "metadata": {},
      "source": [
        "## Partie 2 : Web Scraping avec BeautifulSoup\n",
        "\n",
        "### Qu'est-ce que le Web Scraping ?\n",
        "\n",
        "Le web scraping, c’est l’art d’extraire des infos d’un site web de manière automatisée.\n",
        "\n",
        "Dans la partie précédente, je t’ai donné la grande nouvelle… Toutes les pages web sont accessibles via un simple **GET**.\n",
        "\n",
        "➡️  Mais parfois, les données que tu attends ne sont pas là directement. Au lieu des articles, tu ne récupères que le squelette 🩻 du site. Pourquoi ? Parce que le site fait peut-être appel à une API en arrière-plan qui met du temps à répondre. Résultat : tu te retrouves avec une page vide ou incomplète.\n",
        "\n",
        "Nous n'aurons pas à traiter cet éxemple dans ce cours, mais si tu veux une piste pour régler ce type de problème tu peux te tourner vers **Selenium** pour scraper des sites en python. \n",
        "\n",
        "**En résumé :**\n",
        "\n",
        "-\tSi la page est rendue via JavaScript (comme un site dynamique où les données arrivent après un certain temps), utilise **Selenium**.\n",
        "-\tSi les données sont dans le HTML dès le chargement initial (pas besoin d’attendre du JS), alors **requests** + **BeautifulSoup** suffisent.\n",
        "\n",
        "**BeautifulSoup** 🍲, c’est une bibliothèque Python qui te permet de naviguer et extraire des données facilement à partir de pages HTML ou XML. En gros, elle t’aide à trouver et parser des éléments dans une page web, comme des titres, des liens, des paragraphes, etc.\n",
        "\n",
        "Tu lui donnes le contenu **HTML** d’une page, et elle te permet de chercher rapidement des trucs comme des **balises** , des **classes**, des **ID**, ou d’autres éléments pour les **scraper**.\n",
        "\n",
        "C’est super pratique quand tu utilises requests ou un autre moyen pour récupérer le HTML d’une page et que tu veux **extraire** des infos spécifiques.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "exemple-scraping",
      "metadata": {},
      "source": [
        "### Éxercice 1 : Extraire les titres des articles d'une page web \n",
        "\n",
        "Rendez-vous 👮🏼‍♂️  sur :\n",
        "- [HackerNews](https://news.ycombinator.com/)\n",
        "\n",
        "Vous êtes censé voir un ensemble d'article un peu comme ça:\n",
        "\n",
        "<div style=\"text-align: center;\">\n",
        "<img src=\"./image/hackernews.png\" width=\"500\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3); border-radius: 10px;\"/>\n",
        "  <figcaption>Interface de Hacker News</figcaption>\n",
        "\n",
        "</div>\n",
        "\n",
        "On peut déja identifier une structure qui se répéte plusieurs fois :\n",
        "  - Des titres\n",
        "  - Des auteurs\n",
        "  - des dates \n",
        "  - des sites \n",
        "\n",
        "Dans toutes cette répétition d'article on peut y voir un composant qui revient très souvent ⬇️ ⬇️ ⬇️:\n",
        "<div style=\"text-align: center;\">\n",
        "<img src=\"./image/bloc_h.png\" width=\"500\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3);border-radius: 10px;\"/>\n",
        "  <figcaption>Composant répétitif d'un article sur Hacker News</figcaption>\n",
        "\n",
        "</div>\n",
        "\n",
        "Pour cet exercice, il va falloir **scraper** sur la page d'hacker news 🏴‍☠️:\n",
        "- Chaque titre \n",
        "- Chaque auteurs\n",
        "\n",
        "\n",
        "Mais **JAMY** comment on fait ca ? 🤓\n",
        "\n",
        "<figure style=\"text-align: center;\">\n",
        "  <img src=\"./image/buthow.jpg\" width=\"300\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3); border-radius: 10px;\"/>\n",
        "  \n",
        "</figure>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a702562e",
      "metadata": {},
      "source": [
        "Quand tu vas sur hacker news, que tu fais clic droit et enfin voir le code source:\n",
        "<figure style=\"text-align: center;\">\n",
        "  <img src=\"./image/option.png\" width=\"500\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3); border-radius: 10px;\"/>\n",
        "  <figcaption>Menu contextuel pour accéder au code source</figcaption>\n",
        "</figure>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83b670cd",
      "metadata": {},
      "source": [
        "Tu arrives sur une page du style:\n",
        "\n",
        "<figure style=\"text-align: center;\">\n",
        "  <img src=\"./image/sourhn.png\" width=\"700\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3); border-radius: 10px;\"/>\n",
        "  <figcaption>Aperçu du code source de Hacker News</figcaption>\n",
        "</figure>\n",
        "\n",
        "Tu commence à avoir une idée ?  🧠\n",
        "\n",
        "Le concept est en soit assez simple, tu dois: \n",
        "1. Identifier dans le code source de la page les informations dont tu as besoin \n",
        "2. Faire une request GET sur le site de hacker news\n",
        "3. Parser tes données avec beautifoulsoup > Donc le code html de la page\n",
        "4. Isoler les élèments dont tu as besoin\n",
        "5. Placer dans une liste tous les titres et tous les auteurs\n",
        "\n",
        "\n",
        "**No worries 🕵🏼‍♂️ nous allons le faire ensemble.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "code-scraping",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "La liste des titres des articles d'hackerNews :\n",
            "[\"Arthur Whitney's one liner sudoku solver (2011) (dyalog.com)\", 'So thieves broke into your storage unit again (oldvcr.blogspot.com)', 'The Data Visualisation Catalogue: find the right method for your data (datavizcatalogue.com)', 'Gokapi: Lightweight selfhosted Firefox Send alternative with AWS S3 support (github.com/forceu)', 'CoRncrete: A corn starch based building material (2017) (tudelft.nl)', 'Sometimes the product innovation is the distribution (interconnected.org)', 'The Remarkable Life of Ibelin (thetimes.com)', 'WordPress Plugin Mirror Downloader (Proof of Concept) (github.com/centminmod)', 'Statisticians use a technique that leverages randomness to deal with the unknown (quantamagazine.org)', 'We need a real GNU/Linux (not Android) smartphone ecosystem (reddit.com)', 'Fuzzing 101 (github.com/antonio-morales)', 'An Intuitive Explanation of Black–Scholes (gregorygundersen.com)', 'Forage conservation is a neglected nitrous oxide source (oup.com)', 'DMNO: Environment Variables Evolved (dmno.dev)', 'Playing with BOLT and Postgres (vondra.me)', 'The Globus INK: a mechanical navigation computer for Soviet spaceflight (righto.com)', 'One pioneering grizzly and her two cubs appear on Vancouver Island (hakaimagazine.com)', 'What P vs. NP is about (vasekrozhon.wordpress.com)', 'I Stayed (zeldman.com)', 'Router Security (routersecurity.org)', 'Show HN: Brisa Framework launch is here | The Web Platform Framework (brisa.build)', 'Continue (YC S23) Is Hiring a Developer Relations Engineer in San Francisco (ycombinator.com)', 'IPU6 camera support in Fedora 41 (hansdegoede.dreamwidth.org)', 'Insecure Deebot robot vacuums collect photos and audio to train AI (abc.net.au)', 'Weird Nonfiction (lareviewofbooks.org)', 'Buildroot (buildroot.org)', 'Arpeggiator Cube (codepen.io)', '\"Extreme\" Broadcom-proposed price hike would up VMware costs 1,050%, AT&T says (arstechnica.com)', 'Getentropy() vs. RAND_bytes() (dotat.at)', 'Wikidata as a Giant Crosswalk File (dbreunig.com)']\n",
            " ainsi que le nombre d'élèments de cette liste: 30\n",
            "La liste des auteurs des articles d'hackerNews :\n",
            "['secwang', 'goldenskye', 'sea-gold', 'thunderbong', 'thunderbong', 'surprisetalk', '_tk_', 'rob', 'Duximo', 'neelc', 'udev4096', 'alexmolas', 'PaulHoule', 'bpierre', 'aquastorm', 'dangle1', 'abscond', 'signa11', 'speckx', 'blueridge', 'aralroca', 'JNRowe', 'testrun', 'samclemens', 'jakogut', 'memalign', 'cebert', 'signa11', 'dbreunig']\n",
            " ainsi que le nombre d'élèments de cette liste: 29\n"
          ]
        }
      ],
      "source": [
        "#Importer les libs dont j'ai besoin\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# URL de la page à scraper\n",
        "url = \"https://news.ycombinator.com/\"\n",
        "\n",
        "# Obtenir le contenu de la page\n",
        "response = requests.get(url)\n",
        "\n",
        "# print(response.text)\n",
        "# # Parser le HTML\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# Cette ligne cherche tous les éléments <span> qui ont la classe CSS 'titleline' dans le document HTML.\n",
        "# Elle utilise la méthode find_all() de l'objet soup (qui est une instance de BeautifulSoup).\n",
        "# Le résultat est une liste de tous ces éléments, qui est stockée dans la variable 'titles'.\n",
        "# Chaque élément de cette liste représente un titre trouvé dans le document HTML, encore dans un type de donnée <class 'bs4.element.ResultSet'>.\n",
        "#il faut pour y récuperer la contenu de chaque titre y accéder avec un .text\n",
        "titles = soup.find_all('span', class_='titleline')\n",
        "\n",
        "#Je construit ma liste de titre ainsi que ma liste d'auteur\n",
        "title_list=[i.text  for i in titles]\n",
        "\n",
        "#Je récupère les auteurs des articles\n",
        "author = soup.find_all('a', class_='hnuser')\n",
        "\n",
        "#Je construit ma liste d'auteur\n",
        "author_list=[i.text  for i in author]\n",
        "\n",
        "\n",
        "print(f\"La liste des titres des articles d'hackerNews :\\n{title_list}\\n ainsi que le nombre d'élèments de cette liste: {len(title_list)}\")\n",
        "print(f\"La liste des auteurs des articles d'hackerNews :\\n{author_list}\\n ainsi que le nombre d'élèments de cette liste: {len(author_list)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2851bdf6",
      "metadata": {},
      "source": [
        "**Good 🎉**\n",
        "\n",
        "Mais on a un petit problème... 🤷🏽‍♂️\n",
        "La liste des titres, n'a pas la même longueur que celle des auteurs. (en espérant que cela soit aussi le cas le jour de la masterclass 🥲)\n",
        "Il faut donc améliorer ce script pour que cela soit exploitable peut-être pour une futur api ? \n",
        "Convertissons en dictionnaire nos deux listes précédentes et de façon structurer s'il vous plaît !\n",
        "\n",
        "Le début reste le même ..\n",
        "\n",
        "À l'inverse de tout à l'heure, au lieu de cibler directement les éléments dont j'ai besoin, je vais essayer de trouver une div plus haute dans la hiérarchie qui englobe tout mon composant. Et j'enchaîne par une for loop afin de récupérer le titre et auteur que je placerais dans une liste de dictionnaires !! 🥵"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "3940ebd6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "  {\n",
            "    \"id\": \"41753741\",\n",
            "    \"title\": \"Arthur Whitney's one liner sudoku solver (2011)\",\n",
            "    \"author\": \"secwang\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"41754008\",\n",
            "    \"title\": \"So thieves broke into your storage unit again\",\n",
            "    \"author\": \"goldenskye\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"41754628\",\n",
            "    \"title\": \"Gokapi: Lightweight selfhosted Firefox Send alternative with AWS S3 support\",\n",
            "    \"author\": \"thunderbong\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"41751407\",\n",
            "    \"title\": \"The Data Visualisation Catalogue: find the right method for your data\",\n",
            "    \"author\": \"sea-gold\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"41752020\",\n",
            "    \"title\": \"CoRncrete: A corn starch based building material (2017)\",\n",
            "    \"author\": \"thunderbong\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"41709429\",\n",
            "    \"title\": \"Sometimes the product innovation is the distribution\",\n",
            "    \"author\": \"surprisetalk\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"41749592\",\n",
            "    \"title\": \"The Remarkable Life of Ibelin\",\n",
            "    \"author\": \"_tk_\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"41747979\",\n",
            "    \"title\": \"Fuzzing 101\",\n",
            "    \"author\": \"udev4096\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"41753092\",\n",
            "    \"title\": \"WordPress Plugin Mirror Downloader (Proof of Concept)\",\n",
            "    \"author\": \"rob\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"41728022\",\n",
            "    \"title\": \"Statisticians use a technique that leverages randomness to deal with the unknown\",\n",
            "    \"author\": \"Duximo\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"41754074\",\n",
            "    \"title\": \"We need a real GNU/Linux (not Android) smartphone ecosystem\",\n",
            "    \"author\": \"neelc\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"41730612\",\n",
            "    \"title\": \"An Intuitive Explanation of Black\\u2013Scholes\",\n",
            "    \"author\": \"alexmolas\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"41752848\",\n",
            "    \"title\": \"Forage conservation is a neglected nitrous oxide source\",\n",
            "    \"author\": \"PaulHoule\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"41712152\",\n",
            "    \"title\": \"DMNO: Environment Variables Evolved\",\n",
            "    \"author\": \"bpierre\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"41743464\",\n",
            "    \"title\": \"Playing with BOLT and Postgres\",\n",
            "    \"author\": \"aquastorm\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"41749612\",\n",
            "    \"title\": \"The Globus INK: a mechanical navigation computer for Soviet spaceflight\",\n",
            "    \"author\": \"dangle1\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"41746482\",\n",
            "    \"title\": \"One pioneering grizzly and her two cubs appear on Vancouver Island\",\n",
            "    \"author\": \"abscond\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"41717543\",\n",
            "    \"title\": \"What P vs. NP is about\",\n",
            "    \"author\": \"signa11\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"41750630\",\n",
            "    \"title\": \"I Stayed\",\n",
            "    \"author\": \"speckx\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"41752327\",\n",
            "    \"title\": \"Router Security\",\n",
            "    \"author\": \"blueridge\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"41749121\",\n",
            "    \"title\": \"Show HN: Brisa Framework launch is here | The Web Platform Framework\",\n",
            "    \"author\": \"aralroca\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"41752864\",\n",
            "    \"title\": \"Continue (YC S23) Is Hiring a Developer Relations Engineer in San Francisco\",\n",
            "    \"author\": null\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"41728185\",\n",
            "    \"title\": \"IPU6 camera support in Fedora 41\",\n",
            "    \"author\": \"JNRowe\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"41753983\",\n",
            "    \"title\": \"Insecure Deebot robot vacuums collect photos and audio to train AI\",\n",
            "    \"author\": \"testrun\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"41752158\",\n",
            "    \"title\": \"Weird Nonfiction\",\n",
            "    \"author\": \"samclemens\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"41752989\",\n",
            "    \"title\": \"Buildroot\",\n",
            "    \"author\": \"jakogut\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"41752081\",\n",
            "    \"title\": \"Arpeggiator Cube\",\n",
            "    \"author\": \"memalign\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"41754314\",\n",
            "    \"title\": \"\\\"Extreme\\\" Broadcom-proposed price hike would up VMware costs 1,050%, AT&T says\",\n",
            "    \"author\": \"cebert\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"41717448\",\n",
            "    \"title\": \"Getentropy() vs. RAND_bytes()\",\n",
            "    \"author\": \"signa11\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"41745591\",\n",
            "    \"title\": \"Wikidata as a Giant Crosswalk File\",\n",
            "    \"author\": \"dbreunig\"\n",
            "  }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "# URL de la page à scraper\n",
        "url = \"https://news.ycombinator.com/\"\n",
        "\n",
        "# Obtenir le contenu de la page\n",
        "response = requests.get(url)\n",
        "\n",
        "# Parser le HTML\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# J'identifie le point d'accroche possibe\n",
        "tr_tags = soup.find_all('tr', class_='athing')\n",
        "\n",
        "#J'ajoute mes id à ma liste tr_tags_list en effectuant le get je récupére l'id de mon tag tr\n",
        "tr_tags_list = [i.get('id') for i in tr_tags]\n",
        "\n",
        "\n",
        "#Fonction lambda pour obtenir le titre et l'auteur\n",
        "get_tr_title = lambda id: (soup.find('tr', id=id).find('span', class_='titleline').find('a').string\n",
        "                           if soup.find('tr', id=id) and soup.find('tr', id=id).find('span', class_='titleline') and\n",
        "                           soup.find('tr', id=id).find('span', class_='titleline').find('a') else None)\n",
        "\n",
        "#Fonction lambda pour obtenir l'auteur\n",
        "get_tr_auteur = lambda id: (soup.find('span', id=f'score_{id}').find_parent('span', class_='subline').find('a', class_=\"hnuser\").string\n",
        "                            if soup.find('span', id=f'score_{id}') and\n",
        "                            soup.find('span', id=f'score_{id}').find_parent('span', class_='subline') and\n",
        "                            soup.find('span', id=f'score_{id}').find_parent('span', class_='subline').find('a', class_=\"hnuser\") else None)\n",
        "\n",
        "final_dict = [{ \"id\": key, \"title\": get_tr_title(key), \"author\": get_tr_auteur(key)} for key in tr_tags_list]\n",
        "print(json.dumps(final_dict, indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67b3a938",
      "metadata": {},
      "source": [
        "________________"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90a02006",
      "metadata": {},
      "source": [
        "Ok, nous allons y aller doucement. 🐢\n",
        "Je vais t'éxpliquer en détail comment ca fonctionne. \n",
        "\n",
        "Premièrement, dans le code source je remarque que je ne peux pas boucler sur une balise avec un **find_all**.\n",
        "\n",
        "Le find_all va me **grouper** tous ceux qu'il va trouver avec les conditions que je lui ai donné ici :\n",
        "- Les balises ```tr```\n",
        "- Qui ont  une balise enfant ```span``` qui possède la classe ```subline```\n",
        "\n",
        "Si cette condition n'est pas réspécté le ```tr``` n'est pas dans ma liste retour. \n",
        "\n",
        "Mon titre et mon auteur sont dans deux balises séparées ... C'est embétant. \n",
        "Nous le voyons bien dans l'image suivante:\n",
        "<div style=\"text-align: center;\">\n",
        "<img src=\"./image/group.png\" width=\"700\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3);border-radius: 10px;\"/>\n",
        "  <figcaption>Composant répétitif d'un article sur Hacker News</figcaption>\n",
        "</div>\n",
        "\n",
        "Il faut donc trouver une solution. \n",
        "Pour ce faire on remarque ca dans le code source: \n",
        "<div style=\"text-align: center;\">\n",
        "<img src=\"./image/reflexion.png\" width=\"700\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3);border-radius: 10px;\"/>\n",
        "  <figcaption>ID répétitif d'un article sur Hacker News</figcaption>\n",
        "</div>\n",
        "\n",
        "Il y a donc bien toujours une **solution** 🎉 \n",
        "\n",
        "Pour récupérer le titre voila ce que je fais dans cette lambda function:\n",
        "\n",
        "````python \n",
        "soup.find('tr', id=id).find('span', class_='titleline').find('a').string\n",
        "````\n",
        "C'est mieux éxpliqué en image: \n",
        "<div style=\"text-align: center;\">\n",
        "<img src=\"./image/firstsoup.png\" width=\"700\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3);border-radius: 10px;\"/>\n",
        "  <figcaption>Première étape de notre lambda function</figcaption>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "explication-scraping",
      "metadata": {},
      "source": [
        "Pour le deuxième bloc c'est un tout petit peu plus tricky:\n",
        "````python\n",
        "soup.find('span', id=f'score_{id}').find_parent('span', class_='subline').find('a', class_=\"hnuser\").string\n",
        "````\n",
        "<div style=\"text-align: center;\">\n",
        "<img src=\"./image/groupsoup2.png\" width=\"700\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3); border-radius: 10px;\"/>\n",
        "  <figcaption>Deuxième étape de notre lambda function</figcaption>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "conclusion",
      "metadata": {},
      "source": [
        "**Well done !! 👌🏼\n",
        "Maintenant c'est à vous de jouer dans l'éxercice 2!**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d88d4db",
      "metadata": {},
      "source": [
        "### Éxercice 2 : À votre tour de scraper !!! ⭐️\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1a1301d",
      "metadata": {},
      "source": [
        "Dans le cadre de cet masterClass, on vous mets gracieusement à disposition un site test de scraping 🎉: \n",
        "- [Site Scraping masterclass 1](https://masterclasdatasscraping.hodi.cloud/)\n",
        "\n",
        "Le but de cet exercice va être le suivant, tu dois avoir exactement les mêmes resultats que cette requête api:\n",
        "\n",
        "````python\n",
        "url_articles = \"https://dashboard-strapi.hodi.cloud/api/articles?fields[0]=id&fields[1]=title&fields[2]=body\"\n",
        "````\n",
        "Qui ressemble à cela:\n",
        "<div style=\"text-align: center;\">\n",
        "<img src=\"./image/newrequeststrapi.png\" width=\"900\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3);border-radius: 10px;\"/>\n",
        "  <figcaption>Requête API de notre exercice</figcaption>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "751a5c4c",
      "metadata": {},
      "source": [
        "Sur le site tu vas avoir une architecture comme celle la:\n",
        "\n",
        "1. Pour la liste des articles\n",
        "<div style=\"text-align: center;\">\n",
        "<img src=\"./image/whatiwant1.png\" width=\"700\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3);border-radius: 10px;\"/>\n",
        "  <figcaption>Le site à scraper</figcaption>\n",
        "</div>\n",
        "\n",
        "2. Pour le corp des articles (le body)\n",
        "<div style=\"text-align: center;\">\n",
        "<img src=\"./image/whatiwant2.png\" width=\"700\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3);border-radius: 10px;\"/>\n",
        "  <figcaption>Un article du site</figcaption>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cc6dee8",
      "metadata": {},
      "source": [
        "Il y à deux petits **pièges** 😬:\n",
        "- Le site à une pagination, promis je ne l'ai pas fait éxprès 🤞🏼\n",
        "- Le body des article se trouve à une autre URL que celle de la page d'acceuil 😇\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93cc1aaa",
      "metadata": {},
      "source": [
        "**Comment te lancer dans cet exercice ? 🚀**\n",
        "1.\tAnalyse bien les données du JSON que tu obtiens avec la requête vers url de l’API précédente. 🧐\n",
        "2.\tRegarde l’URL de la page d’accueil du site et observe comment fonctionne la pagination. Est-ce que l’URL change ou pas ? 🔄\n",
        "3.\tVérifie la page article : de quoi est-elle composée ? Est-ce que j’ai des informations sur la page d’accueil qui me permettent d’accéder directement à la page article ? 🔗\n",
        "4. Est-ce que je peux scraper tout le site avec un simple GET ? ❓ (👉 NON ❗)\n",
        "5. Combien de page j'ai ??? 🙄"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fef1ecc",
      "metadata": {},
      "source": [
        "🎯 Ton objectif : créer une liste de dictionnaires où chaque objet contiendra les champs suivants (bien remplis, bien sûr) :\n",
        "\n",
        "```python\n",
        "scrap_site_data = [\n",
        "  {\"id\": 1, \n",
        "  \"title\": \"Un titre random\", \n",
        "  \"body\": \"Un body random\"},\n",
        "  # etc...\n",
        "]\n",
        "```\n",
        "\n",
        "📋 Pour chaque élément, assure-toi d’inclure :\n",
        "\n",
        "-\tid : l’identifiant unique de l’objet\n",
        "-\ttitle : le titre de l’article ou de la section\n",
        "-\tbody : le contenu ou un résumé de l’article\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c603d937",
      "metadata": {},
      "source": [
        "🚀 Laisse-moi te filer un coup de pouce :\n",
        "\n",
        "-\tL’URL d’un article ressemble à ça : ```/article/{id}```\n",
        "-\tPour naviguer entre les pages, tu dois simplement ajouter ce paramètre à l’URL : ```?page={pageNumber}```.\n",
        "-\tPour trouver l’id… je te laisse fouiller un peu ! 🔍😉 Peut-être dans le code source de la page ? I dont know 🤷🏽‍♂️\n",
        "\n",
        "\n",
        "Voila la checklist qu'on doit valider:\n",
        "- ⬜️ Connaître le nombre de pages de façon programmatique\n",
        "- ⬜️ Scraper le nombre de pages disponibles\n",
        "- ⬜️ Accéder à chaque page pour scraper le body d'un article\n",
        "\n",
        "<div style=\"text-align: center;\">\n",
        "<img src=\"./image/justdoit.jpg\" width=\"400\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3); border-radius: 10px;\"/>\n",
        "  <figcaption>Jimmy neutron fait un haka</figcaption>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d03be90",
      "metadata": {},
      "source": [
        "##### Étape 1 - Récupère le nombre de page 📖"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "45b85fb6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nombre de page: 3\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "urlToGet='https://masterclasdatasscraping.hodi.cloud/'\n",
        "#Je récupère la home page de mon site\n",
        "website = requests.get(urlToGet)\n",
        "\n",
        "#Je le parse avec Bs4\n",
        "soup = BeautifulSoup(website.text, 'html.parser')\n",
        "\n",
        "#Maintenant voyons voir combien de page j'ai\n",
        "pages = soup.find_all('a', class_=re.compile(r'^Home_paginationLink'))\n",
        "print(f\"Nombre de page: {len(pages)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c2d55dc",
      "metadata": {},
      "source": [
        "Dans le code source 💾 de cette page voila ce que je remarque:\n",
        "<div style=\"text-align: center;\">\n",
        "<img src=\"./image/pagination.png\" width=\"700\" style=\"box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3); border-radius: 10px;\"/>\n",
        "  <figcaption>Pagination du site</figcaption>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9882e48c",
      "metadata": {},
      "source": [
        "Mais le **gTxG4** ou encore le **ro1Hj** me fait un peu peur 😱. Du coup, je pense qu’il y a de fortes chances que Home_pagination reste fixe, mais que cet ID mystérieux, probablement généré dynamiquement par la technologie du site, change régulièrement.\n",
        " \n",
        "C’est pour cela que j’utilise cette commande :\n",
        "```python\n",
        "pages = soup.find_all('a', class_=re.compile(r'^Home_pagination'))\n",
        "```\n",
        "\n",
        "Elle demande de chercher la balise ```a``` qui contient une classe commençant par ```Home_pagination```. J’utilise une expression régulière pour m’assurer que cette donnée est bien présente : le symbole ```^``` signifie “**commence par**”.\n",
        "Avec l'expression régulière je n'ai pas besoin de préciser le nom complet de la classe, ici en faisant ```^Home_pagination``` je sais que je vais récupérer tout les éléments qui commencent par Home_pagination. \n",
        "\n",
        "➡️➡️➡️  [Si vous voulez en apprendre plus sur les éxpressions régulieres](https://www.rexegg.com/regex-quickstart.php)  ⬅️⬅️⬅️\n",
        "\n",
        "Notre checklist : \n",
        "- ✅ Connaître le nombre de pages de façon programmatique\n",
        "- ⬜️ Scraper le nombre de pages disponibles\n",
        "- ⬜️ Accéder à chaque page pour scraper le body d'un article\n",
        "\n",
        "Et maintenant, en route pour le grand scrapathon sur le nombre de pages défini plus haut ! 🎉🚀\n",
        "\n",
        "##### Étape 2 - Scraper les n pages et ... accéder à chaque page ...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "840eed5a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "    {\n",
            "        \"id\": \"2\",\n",
            "        \"title\": \"Comment jongler avec des baguettes magiques\",\n",
            "        \"body\": \"Harry Potter nous raconte comment il a appris \\u00e0 jongler avec des baguettes magiques sans accident grave. Apr\\u00e8s un incident f\\u00e2cheux avec Ron et une transformation en escargot, il a perfectionn\\u00e9 sa technique. Maintenant, il ne transforme plus ses amis, mais il conseille de ne pas jongler avec des baguettes emprunt\\u00e9es. Elles ont souvent un caract\\u00e8re capricieux et pourraient d\\u00e9cider d\\u2019invoquer un Basilic au mauvais moment. Bref, le jonglage magique : \\u00e0 pratiquer avec mod\\u00e9ration !\"\n",
            "    },\n",
            "    {\n",
            "        \"id\": \"3\",\n",
            "        \"title\": \"Le guide ultime du sabre laser\",\n",
            "        \"body\": \"Luke Skywalker nous explique que manier un sabre laser, ce n'est pas juste un exercice de style, mais un art ancestral. Il raconte comment son premier duel contre Dark Vador l\\u2019a aid\\u00e9 \\u00e0 mieux comprendre l\\u2019\\u00e9quilibre entre la lumi\\u00e8re et l\\u2019obscurit\\u00e9. Il recommande de commencer avec des melons avant de passer \\u00e0 des combats r\\u00e9els. Si vous vous trouvez \\u00e0 court de batterie, pas de panique : un Jedi astucieux trouvera toujours un chargeur dans une galaxie lointaine. Et rappelez-vous : la Force doit \\u00eatre avec vous, sinon \\u00e7a fait mal !\"\n",
            "    },\n",
            "    {\n",
            "        \"id\": \"4\",\n",
            "        \"title\": \"Le secret du sourire de la Joconde\",\n",
            "        \"body\": \"Sherlock Holmes nous d\\u00e9voile, apr\\u00e8s des ann\\u00e9es de r\\u00e9flexion, la raison du sourire de la Joconde. Ce n\\u2019est ni un secret romantique, ni un complot historique, mais plut\\u00f4t la cons\\u00e9quence d\\u2019une blague secr\\u00e8te racont\\u00e9e par L\\u00e9onard de Vinci pendant la s\\u00e9ance de pose. Holmes a d\\u00e9couvert des notes cach\\u00e9es dans les marges du carnet de Vinci, indiquant qu\\u2019il racontait une blague sur des pigeons et des alchimistes. Voil\\u00e0 pourquoi la Joconde sourit : elle r\\u00e9prime un fou rire d\\u00fb \\u00e0 la blague la plus ancienne de l\\u2019histoire de l\\u2019art !\"\n",
            "    },\n",
            "    {\n",
            "        \"id\": \"5\",\n",
            "        \"title\": \"Comment survivre \\u00e0 une apocalypse zombie\",\n",
            "        \"body\": \"Rick Grimes, h\\u00e9ros de The Walking Dead, partage ses astuces pour survivre \\u00e0 une apocalypse zombie. Il explique que courir n'est pas toujours la meilleure solution, surtout si vous portez des bottes de cow-boy. Il recommande aussi de garder toujours un tournevis \\u00e0 port\\u00e9e de main, car vous ne savez jamais quand vous en aurez besoin pour r\\u00e9parer une porte... ou un zombie. Son dernier conseil ? Apprenez \\u00e0 aimer les conserves. Elles sont \\u00e0 la fois nourrissantes et suffisamment lourdes pour assommer un zombie affam\\u00e9.\"\n",
            "    },\n",
            "    {\n",
            "        \"id\": \"6\",\n",
            "        \"title\": \"Construire son armure en cave\",\n",
            "        \"body\": \"Tony Stark, alias Iron Man, partage ses astuces pour cr\\u00e9er une armure de haute technologie avec un budget r\\u00e9duit. Il raconte comment, au d\\u00e9but de sa carri\\u00e8re, il a construit sa premi\\u00e8re armure avec des pi\\u00e8ces r\\u00e9cup\\u00e9r\\u00e9es dans une cave poussi\\u00e9reuse. Son conseil principal : n\\u2019oubliez jamais les aimants, ils sont essentiels pour que les pi\\u00e8ces tiennent ensemble. Si vous n'avez pas de r\\u00e9acteur Arc \\u00e0 port\\u00e9e de main, Stark recommande de faire preuve de cr\\u00e9ativit\\u00e9 avec des batteries de voiture et quelques ampoules LED pour un look \\u00e0 couper le souffle.\"\n",
            "    },\n",
            "    {\n",
            "        \"id\": \"7\",\n",
            "        \"title\": \"Les meilleures pizzas pour tortues ninja\",\n",
            "        \"body\": \"Michelangelo, la plus gourmande des Tortues Ninja, nous partage ses recettes secr\\u00e8tes de pizzas. Il conseille toujours de rajouter une bonne dose de fromage fondant, et surtout de ne jamais oublier la touche finale : les anchois radioactifs. Selon lui, une pizza sans un peu de mutag\\u00e8ne n\\u2019est pas une vraie pizza. Mais attention, il met en garde : les effets secondaires peuvent inclure des superpouvoirs inattendus ou une envie soudaine de combattre des ninjas. Bref, avec ces recettes, c'est la pizza du futur !\"\n",
            "    },\n",
            "    {\n",
            "        \"id\": \"8\",\n",
            "        \"title\": \"Faire ses courses en Batmobile\",\n",
            "        \"body\": \"Bruce Wayne, alias Batman, partage les d\\u00e9fis inattendus qu\\u2019il rencontre lorsqu\\u2019il utilise la Batmobile pour faire ses courses. Il explique que m\\u00eame si la Batmobile est rapide, se garer dans le parking du supermarch\\u00e9 peut \\u00eatre un cauchemar. En plus, les courses prennent plus de place qu\\u2019on ne le pense dans un v\\u00e9hicule con\\u00e7u pour la chasse aux criminels. Il recommande d\\u2019opter pour un simple panier plut\\u00f4t qu\\u2019un chariot, car les missiles embarqu\\u00e9s prennent d\\u00e9j\\u00e0 beaucoup de place. Son dernier conseil : \\u00e9viter les heures de pointe, m\\u00eame en Batmobile.\"\n",
            "    },\n",
            "    {\n",
            "        \"id\": \"9\",\n",
            "        \"title\": \"L'art du camouflage en for\\u00eat\",\n",
            "        \"body\": \"Katniss Everdeen, h\\u00e9ro\\u00efne de Hunger Games, nous apprend comment se fondre dans le d\\u00e9cor comme un pro. Elle recommande de toujours avoir \\u00e0 port\\u00e9e de main de la boue et quelques feuilles pour un camouflage rapide. Mais attention, se camoufler ne veut pas dire dispara\\u00eetre compl\\u00e8tement : Katniss explique qu\\u2019il faut savoir choisir le bon moment pour bondir et d\\u00e9cocher une fl\\u00e8che. Elle raconte aussi comment elle a utilis\\u00e9 ces techniques pour \\u00e9chapper \\u00e0 plusieurs pi\\u00e8ges mortels et d\\u00e9crocher la victoire.\"\n",
            "    },\n",
            "    {\n",
            "        \"id\": \"10\",\n",
            "        \"title\": \"Les vertus du miel magique\",\n",
            "        \"body\": \"Winnie l'Ourson partage ses r\\u00e9flexions profondes sur l\\u2019importance du miel dans sa vie. Il explique que le miel, au-del\\u00e0 de son go\\u00fbt d\\u00e9licieux, est un v\\u00e9ritable \\u00e9lixir de bonheur. Selon Winnie, chaque pot de miel raconte une histoire, une aventure en for\\u00eat avec ses amis. Il recommande de toujours avoir un pot \\u00e0 port\\u00e9e de main pour les moments de r\\u00e9flexion philosophique. Cependant, il met en garde : le miel est un tr\\u00e9sor \\u00e0 partager avec ses amis, car tout est meilleur quand on est bien entour\\u00e9.\"\n",
            "    },\n",
            "    {\n",
            "        \"id\": \"11\",\n",
            "        \"title\": \"Pourquoi les aliens adorent les v\\u00e9los\",\n",
            "        \"body\": \"E.T., le c\\u00e9l\\u00e8bre extraterrestre, nous explique pourquoi il pr\\u00e9f\\u00e8re les balades \\u00e0 v\\u00e9lo plut\\u00f4t que de voler en soucoupe volante. Selon lui, le v\\u00e9lo offre une sensation de libert\\u00e9 que les voyages interstellaires ne peuvent pas \\u00e9galer. Il raconte comment, lors de sa premi\\u00e8re balade sous la pleine lune avec Elliott, il a ressenti un lien particulier avec la Terre et ses habitants. E.T. conseille \\u00e0 tout le monde de prendre le temps d\\u2019appr\\u00e9cier une balade \\u00e0 v\\u00e9lo et de ne pas toujours chercher des moyens de transport plus rapides.\"\n",
            "    },\n",
            "    {\n",
            "        \"id\": \"12\",\n",
            "        \"title\": \"Article de la masterclass\",\n",
            "        \"body\": \"blablablablablablablablablablablablablablablabla blablablablablablablablablablablabla blablablablablablablablablablablablablablablablablablablabla blablablablablablablablablablablablablablablablablablablabla\"\n",
            "    }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "# Importation des bibliothèques nécessaires\n",
        "import requests  # Pour faire des requêtes HTTP\n",
        "from bs4 import BeautifulSoup  # Pour analyser le HTML\n",
        "import re  # Pour utiliser des expressions régulières\n",
        "import json  # Pour formater les données en JSON (ajouté car utilisé à la fin)\n",
        "\n",
        "# Définition d'une fonction lambda pour construire l'URL\n",
        "# Cette fonction prend un argument et le combine avec l'URL de base\n",
        "urlToGet = lambda arguments: f'https://masterclasdatasscraping.hodi.cloud/{arguments}'\n",
        "\n",
        "# Initialisation d'une liste vide pour stocker les données finales\n",
        "final_dict = []\n",
        "\n",
        "# Boucle sur les pages 1 à 3\n",
        "for page in range(1, 4):\n",
        "    # Récupération du contenu de la page\n",
        "    website = requests.get(urlToGet(f'?page={page}'))\n",
        "\n",
        "    # Analyse du HTML avec BeautifulSoup\n",
        "    soup = BeautifulSoup(website.text, 'html.parser')\n",
        "\n",
        "    # Recherche de tous les articles sur la page\n",
        "    articles = soup.find_all('div', class_=re.compile(r'^ArticleCard_articleCard'))\n",
        "\n",
        "    # Pour chaque article trouvé\n",
        "    for article in articles:\n",
        "        # Extraction de l'ID de l'article\n",
        "        id_article = article.get(\"id\").split('-')[1]\n",
        "\n",
        "        # Extraction du titre de l'article\n",
        "        title_article = article.find('h2', class_=re.compile(r'^ArticleCard_articleTitle')).text\n",
        "\n",
        "        # Récupération du contenu détaillé de l'article\n",
        "        body = requests.get(urlToGet(f'/article/{id_article}'))\n",
        "        body_soup = BeautifulSoup(body.text, 'html.parser')\n",
        "\n",
        "        # Extraction du corps de l'article\n",
        "        body_article = body_soup.find('p', class_=re.compile(r'^ArticlePage_body')).text\n",
        "\n",
        "        # Ajout des informations de l'article au dictionnaire final\n",
        "        final_dict.append({\"id\": id_article, \"title\": title_article, \"body\": body_article})\n",
        "\n",
        "# Affichage du résultat final en format JSON avec une indentation de 4 espaces\n",
        "print(json.dumps(final_dict, indent=4))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "973eb237",
      "metadata": {},
      "source": [
        "**Notre checklist 🎉:**\n",
        "- ✅ Connaître le nombre de pages de façon programmatique\n",
        "- ✅ Scraper le nombre de pages disponibles\n",
        "- ✅ Accéder à chaque page pour scraper le body d'un article\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f952657",
      "metadata": {},
      "source": [
        "<div style=\"text-align: center;\">\n",
        "<iframe src=\"https://giphy.com/embed/d3mlE7uhX8KFgEmY\" width=\"480\" height=\"269\" style=\"\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe>\n",
        "<p><a href=\"https://giphy.com/gifs/culture--think-hmm-d3mlE7uhX8KFgEmY\"></a></p>\n",
        "<figcaption>Bien joué à tous</figcaption>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67591b36",
      "metadata": {},
      "source": [
        "## Conclusion : Ce que vous avez appris aujourd'hui ! 🎓🚀\n",
        "\n",
        "1. Les API, c'est la vie ! 🌐\n",
        "   - Méthodes HTTP (GET, POST, etc.) 📡\n",
        "   - Status codes (200 OK, 404 Not Found, etc.) 🚦\n",
        "   - Paramètres d'URL pour filtrer les données 🔍\n",
        "\n",
        "2. Requests, votre nouveau meilleur ami 🤝\n",
        "   - Faire des requêtes HTTP en Python 🐍\n",
        "   - Récupérer et traiter les réponses JSON 📊\n",
        "\n",
        "3. Web Scraping avec BeautifulSoup 🍲\n",
        "   - Extraire des données de pages HTML 🕷️\n",
        "   - Naviguer dans la structure d'une page web 🧭\n",
        "\n",
        "4. Techniques avancées de scraping 🥷\n",
        "   - Gérer la pagination 📄\n",
        "   - Extraire des données de plusieurs pages 📚\n",
        "   - Construire des datasets structurés 🏗️\n",
        "\n",
        "5. Bonnes pratiques et astuces 💡\n",
        "   - Utiliser les expressions régulières 🔬\n",
        "   - Optimiser vos scripts de scraping ⚡\n",
        "\n",
        "Vous êtes maintenant prêts à conquérir le monde des données web ! 🌍💪\n",
        "N'oubliez pas : avec un grand pouvoir viennent de grandes responsabilités. Scrapez éthiquement ! 🦸‍♂️🦸‍♀️"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8755895b",
      "metadata": {},
      "source": [
        "## Mémo des ressources 📚🔗\n",
        "\n",
        "Voici un récapitulatif de toutes les ressources et URLs utiles mentionnées dans ce cours :\n",
        "\n",
        "### APIs et Documentation 🌐\n",
        "\n",
        "- [Documentation de Strapi](https://docs.strapi.io/dev-docs/api/rest/populate-select)\n",
        "  Pour comprendre comment utiliser les paramètres dans les requêtes API Strapi.\n",
        "\n",
        "- [Open Data Hub de la Région Réunion](https://data.regionreunion.com/explore)\n",
        "  Exemple d'API publique .\n",
        "\n",
        "### Outils de développement 🛠️\n",
        "\n",
        "- [Basic JSON Formatter pour Firefox](https://addons.mozilla.org/en-US/firefox/addon/basic-json-formatter/)\n",
        "- [JSON Formatter pour Chrome](https://chromewebstore.google.com/detail/json-formatter/bcjindcccaagfpapjjmafapmmgkkhgoa)\n",
        " \n",
        "\n",
        "### Sites pour pratiquer le scraping 🕷️\n",
        "\n",
        "- [Hacker News](https://news.ycombinator.com/)\n",
        "  Site utilisé pour les exercices de scraping.\n",
        "\n",
        "- [Site de scraping MasterClass](http://localhost:3000)\n",
        "  Site spécialement conçu pour pratiquer vos compétences en scraping.\n",
        "\n",
        "### Ressources d'apprentissage supplémentaires 📖\n",
        "\n",
        "- [Explication des méthodes REST](https://blog.postman.com/what-are-http-methods/)\n",
        "  Pour approfondir votre compréhension des méthodes HTTP.\n",
        "\n",
        "- [Guide rapide des expressions régulières](https://www.rexegg.com/regex-quickstart.php)\n",
        "  Pour maîtriser les regex utilisées dans le scraping avancé.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
